{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Getting Started with the Microsoft Semantic Kernel\"\n",
        "page-layout: full\n",
        "toc: true\n",
        "toc-expand: true\n",
        "---"
      ],
      "id": "16416b5d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with the Microsoft Semantic Kernel\n",
        "\n",
        "## What is the Microsoft Semantic Kernel\n",
        "\n",
        "Itâ€™s a thin, open-source, Software Development Toolkit to interact with AI services, mostly LLMs, and for now, mostly OpenAI.\n",
        "\n",
        "It was originally designed to power the Microsoft Copilots, such as Microsoft 365 and Bing, initially in C#, but now extended to Python and Java and released to the developer community.\n",
        "\n",
        "SK in C# has a few more features than Python, but Python is catching up fast. There are some features that only exist in Python at the moment (notably, HuggingFace models). \n",
        "\n",
        "## Differences from LangChain\n",
        "\n",
        "- Semantic Kernel was designed to be more customizable than LangChain. This gives you more control but requires more coding.\n",
        "- If you only need LLM functionality, LangChain will probably get you to a prototype or MVP quicker. \n",
        "- Semantic Kernel was designed to help easily add LLM features to enterprise or large-scale consumer applications.\n",
        "- If you use Python, you can use both. \n",
        "- If you use JavaScript, you can use LangChain, but not Semantic Kernel.\n",
        "- If you use Java or .NET, you can use Semantic Kernel, but not LangChain.\n",
        "\n",
        "# A whirlwind tour through Semantic Kernel in Python\n",
        "\n",
        "In the post below, I'll quickly show how to get started with Semantic Kernel in Python using an Azure subscription.\n",
        "\n",
        "## The Kernel\n",
        "\n",
        "The Semantic Kernel is just a lightweight object where you will attach everything you need to complete your AI tasks.\n"
      ],
      "id": "fda9e68c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import semantic_kernel as sk\n",
        "kernel = sk.Kernel()"
      ],
      "id": "bde4c9b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connectors\n",
        "\n",
        "Connectors are the way you connect to AI services. You can connect multiple services to the same kernel, which allows you to perform a complex task using different services for each step.\n",
        "\n",
        "For example, my subscription has two models deployed: one deployment named `gpt35` the GPT 3.5 Turbo model and one deployment named `gpt4` for a deployment of the GPT-4 model. I can load both of them into the kernel with the code below:\n"
      ],
      "id": "8068aec8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
        "\n",
        "gpt35 = AzureChatCompletion(deployment_name=\"gpt35\", # yours may be different\n",
        "endpoint=OPENAI_ENDPOINT,\n",
        "api_key=OPENAI_API_KEY)\n",
        "\n",
        "gpt4 = AzureChatCompletion(\n",
        "    deployment_name=\"gpt4\", # yours may be different\n",
        "endpoint=OPENAI_ENDPOINT,\n",
        "api_key=OPENAI_API_KEY)\n",
        "\n",
        "kernel.add_chat_service(\"gpt35\", gpt35)\n",
        "kernel.add_chat_service(\"gpt4\", gpt4)"
      ],
      "id": "960e6f84",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}