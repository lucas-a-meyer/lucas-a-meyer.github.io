<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Lucas A. Meyer</title>
<link>https://www.meyerperin.com/index.html</link>
<atom:link href="https://www.meyerperin.com/index.xml" rel="self" type="application/rss+xml"/>
<description>Lucas A. Meyer&#39;s blog</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Sun, 07 Jan 2024 08:00:00 GMT</lastBuildDate>
<item>
  <title>Creating an Azure Web App with Authentication</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2024-01-07-app-with-authorization.html</link>
  <description><![CDATA[ 



<p>This is the first post in a series of posts about creating a web app to manage my social media. The main page for this series is <a href="../posts/2024-01-05-thread_manager.html">here</a>.</p>
<p>We begin by <a href="https://learn.microsoft.com/en-us/azure/app-service/quickstart-python?tabs=django%2Cwindows%2Cazure-portal%2Cvscode-deploy%2Cdeploy-instructions-azportal%2Cterminal-bash%2Cdeploy-instructions-zip-azcli#2---create-a-web-app-in-azure">creating a new App Service in Azure using the Azure Portal</a>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>I did not use the sample code in section 1 from the link above, because I intended to use the code that uses the Microsoft Authentication Library (MSAL) for Python. <strong>I just created an empty app.</strong></p>
</div>
</div>
<p>From the defaults, I changed the App plan to a cheaper plan. The free plan (F1) also works. I also configured the app to use the Python 3.11 runtime, which is the version I’m using to develop.</p>
<p>I then <a href="https://learn.microsoft.com/en-us/azure/app-service/deploy-continuous-deployment?tabs=github">configured the app to sync with GitHub for continuous deployment</a>, so that the app automatically updates in production when I push changes to GitHub. I simply followed the instructions on the link, which are very straightfoward: I selected GitHub as the source, authorized Azure to access my GitHub account, selected the repository and branch, and then selected the option to deploy the code automatically when I push changes to GitHub.</p>
<section id="configuring-microsoft-entra-id-and-linking-the-app" class="level2">
<h2 class="anchored" data-anchor-id="configuring-microsoft-entra-id-and-linking-the-app">Configuring Microsoft Entra ID and Linking the App</h2>
<p>Ultimately, I want to ensure that users are only allowed to see the app if they are authorized. To do this, I will use Microsoft Entra ID to authenticate users. To get to that, we first need to <strong><em>authenticate</em></strong> the users, and then <strong><em>authorize</em></strong> them to access the app. This post is about the authentication part.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Authentication is the process of verifying a user’s identity, typically using credentials like usernames and passwords. Authorization, on the other hand, determines if an authenticated user has permissions to access certain resources or perform specific actions. While authentication confirms who the user is, authorization decides what an authenticated user is allowed to do. Authentication is the first step, necessary before authorization can be applied to manage access and permissions.</p>
</div>
</div>
<p>To create an app that does authentication, I followed the instructions at <a href="https://learn.microsoft.com/en-us/entra/identity-platform/quickstart-web-app-python-sign-in?tabs=windows">Quickstart: Sign in users and call the Microsoft Graph API from a Python web app</a>. The instructions will tell you where to find the <code>CLIENT_ID</code> and how to generate a <code>CLIENT_SECRET</code> for the app. The <code>AUTHORITY</code> needs to be set to <code>AUTHORITY="https://login.microsoftonline.com/&lt;tenant_id&gt;"</code>, which I obtained from the Azure Portal, in the Overview page of Microsoft Entra ID.</p>
<p>I downloaded the full code for the app, and the only change I had to make was to create an <code>.env</code> file with the variables described above. This is not required for the app to run on the web, but it helps when running locally.</p>
<p>The <code>.env</code> file should look like this:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">CLIENT_ID</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">client_id</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb1-2"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">CLIENT_SECRET</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">client_secret</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb1-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">AUTHORITY</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>https://login.microsoftonline.com/<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">tenant_id</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">]</span></span></code></pre></div>
<p>The instructions don’t mention this, but after finishing the instructions, you also have to link the Entra ID configuration to the Web App you created in the first step. To do this, go to the Azure Portal, open the App Service, go to the “Authentication” tab, and click on “Microsoft” under “Identity providers”. Then, select the “Existing App” tab and select the app you created in the previous step.</p>
<p>The final connection step was to set up the environment variables <code>CLIENT_ID</code>, <code>CLIENT_SECRET</code> and <code>AUTHORITY</code> in the App Service. I followed the instructions on <a href="https://docs.microsoft.com/en-us/azure/app-service/configure-common#configure-app-settings">this link</a> to set the environment variables in the Web App to the same values present in the .env file.</p>
<p>Once I did all this, I pushed my code to GitHub and it was automatically deployed to the App Service.</p>
</section>
<section id="code-walkthrough" class="level2">
<h2 class="anchored" data-anchor-id="code-walkthrough">Code walkthrough</h2>
<p>The code is for a <a href="https://flask.palletsprojects.com/en/3.0.x/">Flask</a> Web App. Flask is a Python framework for building web apps. I decided to use it instead of other alternatives like Angular or NextJS because it allows me to use Python, which is the language I’m most familiar with. The code is in the <a href="https://github.com/lucas-a-meyer/thread-manager/blob/65a6fe606281ab89b55b9e6add9fd476c3b0d024/app.py"><code>app.py</code></a> file, and I will walk through it below. I also created an <code>app_config.py</code> file to store the configuration variables, which you can see in GitHub <a href="https://github.com/lucas-a-meyer/thread-manager/blob/main/app_config.py">here</a>. I will not walk through the <code>app_config.py</code> file, because it is just a file to store the configuration variables.</p>
<section id="the-app.py-file" class="level3">
<h3 class="anchored" data-anchor-id="the-app.py-file">The app.py file</h3>
<p>The first thing we do is import the libraries we will use. The <code>identity.web</code> library is the one that does the authentication. The <code>requests</code> library is used to make HTTP requests. The <code>Flask</code> library is the framework we are using to build the web app. The <code>redirect</code>, <code>render_template</code>, <code>request</code>, <code>session</code>, and <code>url_for</code> libraries are all from Flask. The <code>Session</code> library is used to store the session information. The <code>app_config</code> library is the one we created to store the configuration variables.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> identity.web</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> requests</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> flask <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Flask, redirect, render_template, request, session, url_for</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> flask_session <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Session</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> app_config</span>
<span id="cb2-7"></span>
<span id="cb2-8">__version__ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.7.0"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The version of this sample, for troubleshooting purpose</span></span>
<span id="cb2-9"></span>
<span id="cb2-10">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Flask(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span>)</span>
<span id="cb2-11">app.config.from_object(app_config)</span>
<span id="cb2-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">assert</span> app.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"REDIRECT_PATH"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"REDIRECT_PATH must not be /"</span></span></code></pre></div>
<p>The next thing we do is create a session. This is used to store the session information. The <code>Session</code> library is used to store the session information. The <code>app.jinja_env.globals.update(Auth=identity.web.Auth)</code> is not used in my code.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">Session(app)</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This section is needed for url_for("foo", _external=True) to automatically</span></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># generate http scheme when this sample is running on localhost,</span></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># and to generate https scheme when it is deployed behind reversed proxy.</span></span>
<span id="cb3-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># See also https://flask.palletsprojects.com/en/2.2.x/deploying/proxy_fix/</span></span>
<span id="cb3-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> werkzeug.middleware.proxy_fix <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ProxyFix</span>
<span id="cb3-8">app.wsgi_app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ProxyFix(app.wsgi_app, x_proto<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, x_host<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-9"></span>
<span id="cb3-10">app.jinja_env.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">globals</span>.update(Auth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>identity.web.Auth)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Useful in template for B2C</span></span>
<span id="cb3-11">auth <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> identity.web.Auth(</span>
<span id="cb3-12">    session<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>session,</span>
<span id="cb3-13">    authority<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>app.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AUTHORITY"</span>],</span>
<span id="cb3-14">    client_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>app.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CLIENT_ID"</span>],</span>
<span id="cb3-15">    client_credential<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>app.config[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CLIENT_SECRET"</span>],</span>
<span id="cb3-16">)</span></code></pre></div>
<p>The next thing we do is create a route for the login page. The <code>@app.route("/login")</code> is a decorator that tells Flask that the function below it is a route for the login page. The <code>render_template</code> function renders the <code>login.html</code> template, which is the login page.</p>
<p>The important line in the login template is <a href="https://github.com/lucas-a-meyer/thread-manager/blob/65a6fe606281ab89b55b9e6add9fd476c3b0d024/templates/login.html#L19">line 19</a>, which initiates the login process by directing the user to the <code>auth_response</code>route, which is the same as <code>app_config.REDIRECT_PATH</code>.</p>
<p>The <code>auth.log_in</code> function comes from the <code>identity.web</code> library, and returns a dictionary with the information needed to log in. The <code>scopes</code> parameter is used to tell the user what the app will be able to do on their behalf (in my case, just read their basic information). The <code>redirect_uri</code> parameter is optional, must match the redirect URI registered in the Azure Portal. The <code>prompt</code> parameter is also optional, and it can take different values, which are defined in <a href="https://openid.net/specs/openid-connect-core-1_0.html#AuthRequest">this link</a>.</p>
<p>If the authentication is successful, the <code>auth_response</code> route will be called. If the authentication is not successful, the <code>auth_error.html</code> template will be rendered.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@app.route</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/login"</span>)</span>
<span id="cb4-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> login():</span>
<span id="cb4-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> render_template(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"login.html"</span>, version<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>__version__, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>auth.log_in(</span>
<span id="cb4-4">        scopes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>app_config.SCOPE, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Have user consent to scopes during log-in</span></span>
<span id="cb4-5">        redirect_uri<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>url_for(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"auth_response"</span>, _external<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>), </span>
<span id="cb4-6">        prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"select_account"</span>,  </span>
<span id="cb4-7">        ))</span></code></pre></div>
<p>The next thing we do is create a route for the <code>auth_response</code> page. The <code>auth.complete_log_in(request.args)</code> function is from the <code>identity.web</code> library, and it returns a dictionary with the result of the log in process, which can be successful or an error, in which case it will contain an error message.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@app.route</span>(app_config.REDIRECT_PATH)</span>
<span id="cb5-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> auth_response():</span>
<span id="cb5-3">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> auth.complete_log_in(request.args)</span>
<span id="cb5-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"error"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> result:</span>
<span id="cb5-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> render_template(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"auth_error.html"</span>, result<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>result)</span>
<span id="cb5-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> redirect(url_for(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"index"</span>))</span></code></pre></div>
<p>If the login was successful, we show the <a href="https://github.com/lucas-a-meyer/thread-manager/blob/65a6fe606281ab89b55b9e6add9fd476c3b0d024/templates/index.html">index page</a>, which lists the information we collected about the user from the authentication provider.</p>
<p>I am only using Microsoft Accounts (formerly Live, currently used in Xbox and Outlook.com) as the authentication provider for now. I may add Google Accounts later, but I don’t intend to manage my own authentication, even though the code supports it.</p>
<p>I call the function <code>auth.get_user()</code> from the <code>identity.web</code> library, and it returns a dictionary with the information about the user. The <code>render_template</code> function renders the <code>index.html</code> template, which is the index page. The <code>user</code> parameter is used to pass the user information to the template. The index page will display the user name and the subscription ID.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@app.route</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/"</span>)</span>
<span id="cb6-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> index():</span>
<span id="cb6-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> auth.get_user():</span>
<span id="cb6-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> redirect(url_for(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"login"</span>))</span>
<span id="cb6-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> render_template(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index.html'</span>, user<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>auth.get_user(), version<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>__version__)</span>
<span id="cb6-6"></span>
<span id="cb6-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb6-8">    app.run()</span></code></pre></div>
</section>
</section>
<section id="testing" class="level2">
<h2 class="anchored" data-anchor-id="testing">Testing</h2>
<p>I navigated to the app URL and was able to sign in with my Microsoft account. I was then redirected to the app, where I could see the information about my login.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.meyerperin.com/images/thread_manager/step1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Successful log in</figcaption>
</figure>
</div>
<p>Now that I have an app that can authenticate users, I need to work on authorization, so that only authorized users can access the app.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2024-01-07-app-with-authorization.html</guid>
  <pubDate>Sun, 07 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/azure-web-app.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Automatically adding meta tags to your blog posts with OpenAI</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2024-01-06-automatically-adding-descriptions.html</link>
  <description><![CDATA[ 



<p>As I was updating my blog, I realized that I had forgotten to add the <code>description</code> meta tag to many of my blog posts. This is the text that appears in search results and when you share a link on social media. I didn’t want to go through all my posts and add a description manually, so I decided to use OpenAI GPT to generate descriptions for me.</p>
<p>This code is very simple, but it may be useful to you, so I’m sharing it here. It’s written in Python and uses the new <a href="https://github.com/openai/openai-python/discussions/742">OpenAI Python client syntax</a>.</p>
<section id="the-code" class="level2">
<h2 class="anchored" data-anchor-id="the-code">The code</h2>
<p>My blog is written in Quarto, which is a Markdown-based document format. I use Quarto Markdown (<code>.qmd</code>) files to write my blog posts. A <code>.qmd</code> file is a Markdown file with YAML front matter. The YAML front matter contains metadata about the document, such as the title, author, and date. I wanted to add the <code>description</code> meta tag to the YAML front matter of each file.</p>
<p>The first thing to do is to extract the YAML front matter from the file. I used a regular expression to do this. If the file doesn’t contain YAML front matter, I will skip it.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> yaml</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dotenv <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dotenv</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> parse_qmd(content):</span>
<span id="cb1-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extract the YAML front matter</span></span>
<span id="cb1-9">    matches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.findall(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'^---\n(.*?)\n---'</span>, content, re.DOTALL)</span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">not</span> matches:</span>
<span id="cb1-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb1-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> matches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], content</span></code></pre></div>
<p>I wrote a function to recompose the file content after modifying the YAML front matter. This function takes the original YAML front matter, the modified YAML data, and the full file content as input. It replaces the original YAML front matter with the modified YAML data and returns the updated file content.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> recompose_qmd(yaml_data, original_yaml, content):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert the modified YAML data to string</span></span>
<span id="cb2-3">    new_yaml_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> yaml.dump(yaml_data, default_flow_style<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb2-4"></span>
<span id="cb2-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Replace the original YAML content with the new one</span></span>
<span id="cb2-6">    updated_content <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> content.replace(original_yaml, new_yaml_str)</span>
<span id="cb2-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> updated_content</span></code></pre></div>
<p>The workhorse of this code is the part that generates a summary of the Markdown content. I used the OpenAI chat API to do this. I created a chat prompt that asks the user to describe what the reader will learn after reading the article. I then used the <code>gpt-4</code> model to generate a response to this prompt. The response is the summary of the article.</p>
<p>In my first attempts, GPT was starting the summary with “After reading the markdown article, the reader will learn”. I didn’t want this, so I added some text and an example to the prompt to remove this behavior.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> summarize_markdown(markdown):</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load your OpenAI API key</span></span>
<span id="cb3-3"></span>
<span id="cb3-4">    client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI(</span>
<span id="cb3-5">        api_key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'OPENAI_API_KEY'</span>)</span>
<span id="cb3-6">    )</span>
<span id="cb3-7"></span>
<span id="cb3-8">    chat_completion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat.completions.create(</span>
<span id="cb3-9">    messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb3-10">        {</span>
<span id="cb3-11">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>,</span>
<span id="cb3-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""Without repeating 'After reading the markdown article, the reader will learn', </span></span>
<span id="cb3-13"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">            describe in one sentence what the reader will learn about after reading the markdown article. </span></span>
<span id="cb3-14"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">            Also don't say 'the reader will learn about', just say what they'll learn. For example, </span></span>
<span id="cb3-15"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">            instead of saying 'the reader will learn about strategies for programming', </span></span>
<span id="cb3-16"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">            just say 'strategies for programming' </span></span>
<span id="cb3-17"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">            Markdown:</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span></span>
<span id="cb3-18"><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">            </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>markdown<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span>,</span>
<span id="cb3-19">        }</span>
<span id="cb3-20">    ],</span>
<span id="cb3-21">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4"</span>)</span>
<span id="cb3-22"></span>
<span id="cb3-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> chat_completion.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content</span></code></pre></div>
<p>Finally, I wrote a function that processes all the <code>.qmd</code> files in a directory. It loops through all the files in the directory and calls the functions I wrote above to extract the YAML front matter, generate a summary of the Markdown content, and add the summary to the YAML front matter.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> process_qmd_files(directory):</span>
<span id="cb4-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Loop through all files in the directory</span></span>
<span id="cb4-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> filename <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> os.listdir(directory):</span>
<span id="cb4-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> filename.endswith(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.qmd'</span>):</span>
<span id="cb4-5">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Processing </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>filename<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">...'</span>)</span>
<span id="cb4-6"></span>
<span id="cb4-7">            file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.path.join(directory, filename)</span>
<span id="cb4-8"></span>
<span id="cb4-9">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Read the file</span></span>
<span id="cb4-10">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(file_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'utf-8'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb4-11">                content <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.read()</span>
<span id="cb4-12"></span>
<span id="cb4-13">            original_yaml, full_content <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parse_qmd(content)</span>
<span id="cb4-14">            markdown <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> full_content.replace(original_yaml, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>)</span>
<span id="cb4-15"></span>
<span id="cb4-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> original_yaml <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb4-17">                <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'No YAML front matter found in </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>filename<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, skipping...'</span>)</span>
<span id="cb4-18">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">continue</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Skip files without YAML front matter</span></span>
<span id="cb4-19"></span>
<span id="cb4-20">            yaml_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> yaml.safe_load(original_yaml)</span>
<span id="cb4-21"></span>
<span id="cb4-22">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'description'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> yaml_data:</span>
<span id="cb4-23">                <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'YAML front matter already contains a description, skipping...'</span>)</span>
<span id="cb4-24">                <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">continue</span></span>
<span id="cb4-25"></span>
<span id="cb4-26">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a summary of the Markdown content</span></span>
<span id="cb4-27">            summary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> summarize_markdown(markdown)</span>
<span id="cb4-28"></span>
<span id="cb4-29">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add the summary to the YAML front matter</span></span>
<span id="cb4-30">            yaml_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'description'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> summary</span>
<span id="cb4-31">            </span>
<span id="cb4-32">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Recompose the file content</span></span>
<span id="cb4-33">            updated_content <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> recompose_qmd(yaml_data, original_yaml, full_content)</span>
<span id="cb4-34"></span>
<span id="cb4-35">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Write the updated content back to the file</span></span>
<span id="cb4-36">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(file_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'w'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'utf-8'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb4-37">                <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.write(updated_content)</span>
<span id="cb4-38"></span>
<span id="cb4-39">load_dotenv()</span>
<span id="cb4-40"></span>
<span id="cb4-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Specify the directory containing your .qmd files</span></span>
<span id="cb4-42">directory <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>YOUR_DIRECTORY<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span></span>
<span id="cb4-43"></span>
<span id="cb4-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Process all .qmd files in the directory</span></span>
<span id="cb4-45">process_qmd_files(directory)</span></code></pre></div>
<p>My blog has over 100 documents, and it took less than 2 minutes to add descriptions to all the fields. Using GPT-4 cost me $2.41, but if I was going to do this manually it will have taken me hours. I think it was worth it.</p>
<p>I used my ChatGPT Plus to generate the main block of code that has the function <code>process_qmd_files</code>, so the whole process, end-to-end, took less than 10 minutes.</p>
<p>The complete code is on <a href="https://github.com/lucas-a-meyer/lucas-a-meyer.github.io/blob/main/utils/add_description.py">GitHub</a>.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2024-01-06-automatically-adding-descriptions.html</guid>
  <pubDate>Sat, 06 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/openai-logo.png" medium="image" type="image/png" height="146" width="144"/>
</item>
<item>
  <title>Thread Manager - Managing Social Media</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2024-01-05-thread_manager.html</link>
  <description><![CDATA[ 



<p>Thread Manager a the web app I intend to use to schedule posts to social media sites and run basic analytics.</p>
<p><strong>I’m starting from scratch</strong> as of January 2024, replacing a previous app I wrote to post exclusively to LinkedIn.</p>
<p>I intend to post about the process of building this app on <a href="https://www.threads.net">Threads</a> as I build it. The <a href="https://github.com/lucas-a-meyer/thread-manager">code for this app is on GitHub</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is purely a hobby project. I have a lot of personal commitments and I’ll build this very slowly, as time allows.</p>
</div>
</div>
<section id="why-build-this" class="level1">
<h1>Why build this?</h1>
<p>In 2021, I was writing a lot on LinkedIn, but I was limited by LinkedIn’s post formatting being mostly text — no inline images, no code. To have images and code, I started writing more on my blog, but usually finished my posts in the middle of the night, and I wanted to schedule them to post the next morning. I also wanted to be able to post to multiple social media sites at once. I created a simple app to post to LinkedIn, Twitter and Mastodon, and it worked well enough for my needs.</p>
<p>Now, in 2024, I’m using Threads a lot more, and an API is probably going to be available in 2024. I want to be able to schedule my blog posts to post to Threads, and I also want to share my journey learning the Threads API.</p>
</section>
<section id="technology-choices" class="level1">
<h1>Technology Choices</h1>
<p>Since I work at Microsoft, I am more familiar with Azure than other cloud providers. And since I work in data science, I am more familiar with Python.</p>
<p>My intended technology stack is:</p>
<ul>
<li>Azure App Service to host the app</li>
<li>Azure Cosmos DB to host the data</li>
<li>Azure Functions for the scheduled job (using Python)</li>
<li>Python Flask for the web app, with Bootstrap helping make the UI better</li>
<li><a href="https://www.quarto.org">Quarto</a> for the blog posts</li>
<li>GitHub Pages to hold the blog posts</li>
</ul>
</section>
<section id="project-steps" class="level1">
<h1>Project steps</h1>
<p>The list below shows the steps I am taking to build this app. I will update this list as I make progress.</p>
<ul class="task-list">
<li><input type="checkbox" checked=""><a href="../posts/2024-01-07-app-with-authorization.html">Create an Azure Web App with Authentication and Basic Authorization</a></li>
<li><input type="checkbox">Create a user database in Cosmos DB and link it to authentication</li>
<li><input type="checkbox">Create a user profile page</li>
<li><input type="checkbox">Connect to the LinkedIn API</li>
<li><input type="checkbox">Enable a basic text post to LinkedIn</li>
</ul>
<p>There will be more steps, and I’ll add them as I go.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2024-01-05-thread_manager.html</guid>
  <pubDate>Fri, 05 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/thread_manager_logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Tech reviewers wanted for my Semantic Kernel book</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2024-01-05-review-semantic-kernel.html</link>
  <description><![CDATA[ 



<p>I am wrting a book with <a href="https://www.packtpub.com/">Packt Publishing</a> about the <a href="https://github.com/microsoft/semantic-kernel">Microsoft Semantic Kernel</a>. If you want to help by becoming a technical reviewer, please read on.</p>
<p>The Microsoft Semantic Kernel is an SDK that integrates Large Language Models (LLMs) like <a href="https://platform.openai.com/docs/introduction">OpenAI</a>, <a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service">Azure OpenAI</a>, and <a href="https://huggingface.co/">Hugging Face</a> with conventional programming languages like C# and Python. It allows you to define plugins that can be chained together in just a few lines of code.</p>
<p>The book is called “Essential Guide for the Microsoft Semantic Kernel”, and its intent is to provide a practical, hands-on introduction to the Semantic Kernel.</p>
<section id="reviewers-wanted" class="level2">
<h2 class="anchored" data-anchor-id="reviewers-wanted">Reviewers wanted</h2>
<p>Packt Publishing is looking for technical reviewers to help with the book.</p>
<p>Reviewers need to have some programming experience and familiarity with AI. I don’t know exactly how large is the workload and what are the deadlines, but the book will have between 200 and 250 pages.</p>
<p>Reviewers get:</p>
<ol type="1">
<li>Credit in the book: name and bio printed on the front matter as a Technical Reviewer.</li>
<li>A complimentary print copy of the book at their doorstep.</li>
<li>Free 12-month subscription to all Packt books.</li>
</ol>
<p>This can be a cool way of learning about the Semantic Kernel and AI, while also getting something for it.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>I’m the author of the book, but I’m not involved in the selection of the reviewers, and I don’t know how many reviewers will be selected. I’m just helping Packt to spread the word.</p>
</div>
</div>
<p>If you are interested, please fill the form below and someone from Packt will contact you.</p>
<hr>
<script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
<script>
  hbspt.forms.create({
    region: "na1",
    portalId: "44798468",
    formId: "202dcfb9-d901-4350-abc3-38c9ebee21bf"
  });
</script>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2024-01-05-review-semantic-kernel.html</guid>
  <pubDate>Fri, 05 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/semantic_kernel_book/reviewerW.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Do I Have ADHD? (Work In Progress)</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2024-01-04-adhd.html</link>
  <description><![CDATA[ 



<p>In October 2023, lots of people with ADHD started posting about their experiences on <a href="https://www.threads.net">Threads</a>. Have you ever commuted to work and forgot to bring your laptop? Check. Do you frequently procrastinate a simple two-minute task for several days? Check.</p>
<p>As I started seeing a lot of myself in their experiences, and realized that I developed several coping mechanisms and acquired several coping technologies over time, I decided to go for a full diagnosis.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is a work in progress and it’s still being updated as I go through the process.</p>
<p><strong>I am not a doctor. I am a computer scientist and economist. This is not medical advice. If you suspect you have ADHD, you should talk to a medical professional, like I did.</strong></p>
</div>
</div>
<section id="symptoms" class="level1">
<h1>Symptoms</h1>
<p>Whether I have ADHD or not, I do have some symptoms that are commonly associated with ADHD:</p>
<ul>
<li>Difficulty getting started with tasks, even simple ones. I have gone to appointments I didn’t need to because I didn’t want to call to cancel the appointment.</li>
<li>Difficulty putting the finishing touches on tasks. It takes me 90% of the time to do 90% of the work, and 90% of the time to do the remaining 10% of the work.</li>
<li>I lose an incredible amount of things. When I was a kid, my mom was once told that about 10% of the items of the lost and found in a 300-student school were mine.</li>
<li>I have a hard time focusing on things that are not interesting to me.</li>
<li>I oscillate between hyperfocus and not being able to focus at all.</li>
</ul>
<p>Despite the difficulties, I manage to function well, because I developed a lot of coping mechanisms and technologies over the years.</p>
</section>
<section id="why-i-decided-to-get-tested" class="level1">
<h1>Why I Decided to Get Tested</h1>
<p>The flurry of posts in Threads due to the ADHD awareness month in October 2023 got me started. Several posts described experiences that were very similar to mine. A particular story that resonated a lot with me was the story of someone who was treated for anxiety for years when they in fact had ADHD, and only got diagnosed in their 40s.</p>
<p>I found out that this is a common problem. I have been undergoing treatment for anxiety, and though there was some improvement, progress has been slow. Several posts described a situation similar to mine: people that made little progress while being treated for anxiety, but once diagnosed with and treated for ADHD as adults, their situation improved significantly.</p>
<p>This gave me hope, prompting me to research the diagnostic process. Starting the process ended up being more confusing than helpful. The information I found online described several different processes and tests, some of which even seemed to promise a diagnostic outcome. The best advice came from Threads and it was clear: begin by consulting a medical professional and expressing your concerns, and go from there.</p>
</section>
<section id="the-referral" class="level1">
<h1>The Referral</h1>
<p>The process, at least where I live, seems to be designed to make it hard for people with ADHD to get diagnosed. I had to go through several steps, and I’m still not done. I live in the state of Washington in the United States. The experience may be different in other states or countries.</p>
<p>As mentioned above, the first step is to talk to a medical professional. I had a previously scheduled appointment for my annual physical just a few weeks after I decided to get tested, so I waited for that appointment in mid-October. Trying to schedule a separate appointment would have taken a lot longer.</p>
<p>In the appointment, my PCP told me they would call me with a referral in a couple of days, but instead of calling me, they called my emergency contact, who forgot to tell me about it. Luckily, people in Threads kept reminding me to follow up, and I called my PCP office a few days later. I found the referral and called the psychologist office.</p>
</section>
<section id="the-initial-evaluation" class="level1">
<h1>The Initial Evaluation</h1>
<p>I called the psychologist’s office in early November. The first thing I needed to do was to set up an account in their system, which took a few days. Then, when the account was completed, they asked me to fill several standard medical forms, plus a two-page biography describing why I think I may have ADHD, and three questionnaires designed to assess whether I have ADHD and potentially autism, which tends to happen hand-in-hand. The questionnaires are below:</p>
<ol type="1">
<li><a href="https://l.meyerperin.com/asrs">Adult ADHD Self-Report Scale (ASRS)</a></li>
<li><a href="https://l.meyerperin.com/badds">Brown ADD Scales</a></li>
<li><a href="https://l.meyerperin.com/aq">Autism Spectrum Quotient (AQ)</a></li>
</ol>
<p>The first questionnaire is a screening tool for ADHD. The second is a more detailed questionnaire about ADHD symptoms. The third is a screening tool for Autism Spectrum Disorder (ASD), a common comorbidity. The first six questions serve as a screening tool: if you score in the grey areas for four out of the six questions, you should definitely talk to a medical professional.</p>
<p>I completed the forms December 8th. After all the forms are filled, there are three more appointments to go through, and the first can only be scheduled after the forms are completed. I received a message on the day after that I should schedule the first appointment. I only managed to call back on December 22nd, and scheduled the first evaluation for January 3rd, 2024.</p>
</section>
<section id="the-first-meeting" class="level1">
<h1>The First Meeting</h1>
<p>On Jan 3rd, 2024, I had the first meeting with the psychologist. We introduced ourselves and he asked me about the symptoms that resulted in me seeking a diagnosis. I described the symptoms I listed above, and he asked me to elaborate on each one of them. He also asked me about my childhood, and I described how I was a very good student, but I had a hard time focusing on things that were not interesting to me. I also described how I lost a lot of things, and how I had a hard time getting started with tasks.</p>
<p>He asked about my family history. My mom is definitely not neurotypical, but she has never sought a diagnosis. I did not have enough contact with my dad to know if he was neurotypical or not. He also asked about my children, and I told him that their school has guided me to request accomodation arrangements for them (these are called 504s). I told him that I plan to get them through an ADHD and autism evaluation as well and that the school counselor had already suggested that earlier in the year.</p>
<p>The whole meeting lasted about 40 minutes. We scheduled the appointment for the second meeting on January 8th, 2024.</p>
<p>He then gave me three more tests to fill out on my own time, which I did later at night on that same day.</p>
<ul>
<li><strong>A personality test with over 250 questions:</strong> the test asked a lot about whether I can control other people’s minds, whether I think they control my mind, and how frequently I think about suicide. It also repeated several questions about the <a href="https://www.cdc.gov/ncbddd/adhd/diagnosis.html">usual ADHD symptoms</a>. It would ask “Do you always feel distracted?” and offer four options for me to choose (False, Slightly True, Mostly True, True). Later, it would ask “Do you frequently feel distracted?”, and show the four options again. This one took a while to get through.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits">The Big Five personality test</a>:</strong> a standard personality test with about 50 questions, which was somewhat quick to get through.</li>
<li><strong>An attention test called <a href="https://www.braintrain.com/ivaae2/">IVA-AE2</a>:</strong> this test repeatedly shows an image of a number and speaks another number. For example, it can show 2 and speak “six”. You are assigned two different target numbers, one to click when you see it and another to click when you hear it. It then speaks and shows random numbers for 20 minutes. For example, if you are assigned the number “3 when seen” and “5 when heard”, you should click if it shows 3 and speaks 6, you should also click if it shows 2 and speaks 5, but you should not click when it shows 5 and speaks 3. I think it’s pretty normal to make the mistake of clicking when you hear the number you’re supposed to click only when you see and vice-versa, and I’m sure I made plenty of mistakes, but I think most people would. This test was very tiring.</li>
</ul>
</section>
<section id="coping-technologies" class="level1">
<h1>Coping Technologies</h1>
<p>Over time I acquired a lot of products to help me cope with the symptoms. I will list them below:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Links to Amazon.com are affiliate links. These help the site stay online.</p>
</div>
</div>
<ul>
<li><strong><a href="https://l.meyerperin.com/todo">Microsoft To-Do</a>:</strong> I use Microsoft To-Do to keep track of tasks. I like it because it’s <strong>very</strong> simple, it’s multiplatform, so I can see and check tasks from my phone, my computer and my watch. Since it integrates well with Siri, I can add tasks simply by saying ‘Hey Siri, remind me to X’, which helps me keep track of things. I specifically add tasks to my to-do list as I’m starting them, because that will help me remember to finish if I get distracted.</li>
<li><strong><a href="https://l.meyerperin.com/airtags">Apple AirTags</a>:</strong> I have these on everything since I lose something almost daily. The new AirTags have a feature called Precision Finding that allows me to find things a lot faster, and I use it a lot.</li>
<li><strong><a href="https://l.meyerperin.com/keyring_wallet">Wallet with keyring</a></strong>: A wallet with an attached keyring allows me to carry my badge, car and house keys, wallet, and an AirTag all together, making it hard for me to lose things.</li>
<li><strong><a href="https://l.meyerperin.com/sbiner">S-biner carabiners</a>:</strong> I use these to attach things to my backpack and to each other, so I have only one bundle of items to keep track of.</li>
<li><strong><a href="https://l.meyerperin.com/rayban_meta">Ray-Ban Meta</a>:</strong> works as a headset and as reading glasses. It also has a camera, which I use quite a lot, and an AI that I don’t use as much yet.</li>
<li><strong><a href="https://l.meyerperin.com/ReMarkable2">ReMarkable 2</a>:</strong> during the years, I had (and lost) many notebooks and loose sheets of paper. The ReMarkable2 is an e-ink notebook that feels like a real notebook, but has a lot of capacity. I can also carry academic papers on it.</li>
<li><strong><a href="https://l.meyerperin.com/pillbox">Pillbox</a>:</strong> I use a pillbox to organize my vitamins and medications. I usually forget whether I took the medication or not a few hours after the time I was supposed to take it, so I use the pillbox to keep track of whether I took it or not.</li>
</ul>
</section>
<section id="reactions" class="level1">
<h1>Reactions</h1>
<p>I posted about my experience in Threads, and I got a lot of reactions. Most people are supportive and describe their own experiences being diagnosed. Some people, however, are skeptical. They say that ADHD is overdiagnosed, and that it’s a fad, or a quick excuse to be lazy and forgetful. While I disagree, I have seen some websites that promise a “quick and easy” diagnosis and to get you medications fast. It feels similar to advertisements for Viagra and off-label Ozempic.</p>
</section>
<section id="what-about-you" class="level1">
<h1>What about you?</h1>
<p>If you suspect you may have ADHD, I recommend that you talk to a medical professional. Your PCP is a good place to start. Online communities, such as the ones in Threads, can also be a good place to start.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2024-01-04-adhd.html</guid>
  <pubDate>Thu, 04 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/adhd_heading.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>My experience with the reMarkable 2</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-12-31-remarkable2.html</link>
  <description><![CDATA[ 



<p>Do you want to start journaling in the new year? Tired of carrying notebooks around? Maybe you just want your notes to be more organized?</p>
<p>The reMarkable is a tablet with an e-ink display, similar to the Kindle. It is designed to be used with a stylus, and it is marketed as a paper replacement. Contrary to other tablets, if <em>feels</em> like paper.</p>
<p>I got myself a reMarkable 2 in their Black Friday promotion, after having seen a colleague at work using it. Before having a reMarkable, I used a large number of disorganized Moleskines and loose paper sheets. A lot of loose paper sheets.</p>
<p>I have been using the reMarkable 2 for a little over a month, and I am happy with it. I have used it for taking notes in meetings, for journaling, and for writing down ideas. I have also used it for reading PDFs and ebooks. But it’s not without its issues.</p>
<section id="what-problems-i-want-to-solve" class="level1">
<h1>What problems I want to solve?</h1>
<p>These days, I can take handwritten notes in most of my devices. My main device is a Surface Laptop Studio 2, which folds into a tablet and has a stylus. I also have an iPad Pro 13” with a stylus, but my Surface mostly replaced it. However, I cannot do everything with my Surface Laptop Studio 2. Here are a few of its problems:</p>
<ul>
<li>It is a little on the heavy side. It is heavier than the iPad Pro 13”, that many people already find too heavy for handwritten notes.</li>
<li>Battery life is not great. I can get about 2-3 hours of battery life out of it, which is not enough for a full day of meetings.</li>
<li>It is easy to get distracted by notifications and other apps on the device.</li>
</ul>
</section>
<section id="how-does-the-remarkable-2-solve-these-problems" class="level1">
<h1>How does the reMarkable 2 solve these problems?</h1>
<p>The reMarkable 2 solves these problems in the following ways:</p>
<ul>
<li>The reMarkable 2 is very light. It is 403 grams (0.9 pounds) and 4.7 mm (0.2 inches) thick. For comparison, my iPad Pro 13” is 682 grams (1.5 pounds) and 5.9 mm (0.23 inches) thick.</li>
<li>It has no distractions. It is designed to be used for reading and writing, and it does not have a web browser or any other apps. It is very easy to focus on what you are doing.</li>
<li>It has a very long battery life. I find myself charging it about once or twice a week depending on how much I use it. It charges via USB-C, which is easily available.</li>
</ul>
</section>
<section id="what-is-the-remarkable-2-useful-for" class="level1">
<h1>What is the reMarkable 2 useful for?</h1>
<p>I have been using the reMarkable 2 for the following use cases:</p>
<ul>
<li><strong>Academic paper reading and annotation</strong>: This was my intended use case for the reMarkable 2. The reMarkable 2 works, but it’s not ideal. It has a 10.3” screen, smaller than A4 paper, so I find myself reading papers in landscape mode, which makes the text a little bigger, but requires scrolling. In addition, I don’t like the contrast of the reMarkable’s e-ink display very much. It works, but it doesn’t have contrast adjustments, and it’s not as good as the Kindle’s display.</li>
<li><strong>Journaling</strong>: I have been using the reMarkable 2 for journaling almost every day. The writing experience is exceptional. It really feels like writing on paper, and the experience is very smooth.</li>
<li><strong>Note-taking in meetings</strong>: I have taken the reMarkable 2 to meetings, and this allows me to focus a lot better on meetings. The note-taking is superb, and the lack of distractions is great. The apps in the phone and in the PC allows me to easily see and add to my notes.</li>
<li><strong>Writing down ideas</strong>: I have been using the reMarkable 2 for writing down ideas and think about projects. It works well for that because it allows me to capture my ideas in a way that is easy to share and add to them later, without being distracted by technologies. This is specifically useful when I am in a plane or in a bus commuting.</li>
<li><strong>Many templates</strong>: the reMarkable has many paper templates, including lined paper, grid paper, and even music sheets. You can even create your own templates. I used to have more than one notebook for different purposes, and now I can have them all in the same device.</li>
</ul>
</section>
<section id="downsides" class="level1">
<h1>Downsides</h1>
<p>The reMarkable 2 is not perfect. Here are some of the downsides:</p>
<ul>
<li><p>The reMarkable 2 is expensive, starting at $299 for the barebones model. You need a pen, and you probably want a cover. You can save money by buying unnoficial pens and covers at Amazon. One of my colleagues likes a $20 pen he bought online. The official pen costs $79 without an eraser and $129 with one. Covers run between $79 (cloth) to $199 (leather, with a keyboard).</p></li>
<li><p>You cannot sync Kindle e-books to it. You can read PDFs and e-books on it, but you cannot sync your Kindle library to it.</p></li>
<li><p>Its 10” screen is a little small for reading PDFs. I have been reading a lot of academic papers on it, and it’s easier to do it on landscape mode, where it gets a little bigger, but requires scrolling.</p></li>
<li><p>The lack of contrast is a little annoying. The reMarkable 2 does not have contrast adjustments, and it’s not as good as the Kindle’s display. I find myself looking for better lighting more than I expected.</p></li>
</ul>
</section>
<section id="do-i-recommend-it" class="level1">
<h1>Do I recommend it?</h1>
<p>Although I’m moderately happy with my reMarkable 2, it’s not for everyone and not for every use case.</p>
<p>It replaces my Moleskines and loose paper sheets, but it does not replace my iPad Pro completely: reading Kindle books and academic papers is still better on the iPad Pro.</p>
<p>Reading online reviews, people with ADHD seem to like the reMarkable 2 a lot, because it allows them to focus on what they are doing without distractions. <a href="../posts/2024-01-04-adhd.html">I am not sure yet whether I have ADHD or not</a>, but I likely do, and this may be biasing my opinion towards it.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The reMarkable 2 is, to me, a good replacement for loose paper sheets and Moleskines. A good Moleskine costs $30, so the reMarkable 2, at $299, pays for itself after 10 Moleskines, which is not that far off. It also helps me be more organized, because I can have all my notes in one place, they are always with me and I can easily search them and add to them.</p>
<p>The downsides are still problematic, and it may be better to wait for the next version of the reMarkable. It (barely) works for my use cases, but it may not be for everyone.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Links to Amazon.com are affiliate links. These help the site stay online.</p>
</div>
</div>
<p>You can buy the reMarkable 2 at <a href="https://l.meyerperin.com/rm2">Amazon</a>.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-12-31-remarkable2.html</guid>
  <pubDate>Sun, 31 Dec 2023 08:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/rm2.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Explaining memes and images with the Semantic Kernel and the OpenAI Vision API</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-12-16-skv_py.html</link>
  <description><![CDATA[ 



<p>In this article, I’ll explain how to use the Semantic Kernel and the OpenAI Vision API to perform two tasks:</p>
<ol type="1">
<li>Explain why a meme is funny</li>
<li>Identify an animal in an image and pass the results to another function that generates three interesting facts about the animal.</li>
</ol>
<p>The examples in this article are intentionally simple. The goal of the article is to give you a good idea of the capabilities of the Semantic Kernel and the OpenAI Vision API. The plugin can be used for more complex tasks, such as figuring out whether a street intersection is accessible to wheelchairs,whether a person is wearing a mask, or to automatically generate accessible image descriptions.</p>
<p>The code for all examples can be found in the <a href="https://github.com/lucas-a-meyer/sk-vision-py/blob/main/demo.py">demo.py</a> source file in the <a href="https://l.meyerperin.com/b_skvisionpy">GitHub repository</a>.</p>
<section id="explaining-why-memes-are-funny" class="level1">
<h1>Explaining why memes are funny</h1>
<p>In this first example, I will use the plugin to explain why a meme is funny. My code instantiates and calls the <code>Vision</code> plugin. The plugin has a single function, <code>ApplyPromptToImage</code>, which takes a prompt and an image URL as input, and returns the generated text. In my example, the prompt is simply <code>Why is this meme funny?</code>, and I pass an URL of an image of a meme.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">    </span>
<span id="cb1-2">    kernel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sk.Kernel()</span>
<span id="cb1-3">    vision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel.import_skill(Vision())</span>
<span id="cb1-4"></span>
<span id="cb1-5">    meme_base_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://raw.githubusercontent.com/lucas-a-meyer/lucas-a-meyer.github.io/main/images/"</span></span>
<span id="cb1-6">    meme_url_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"meme1.jpg"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"meme2.png"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"meme3.jpg"</span>] </span>
<span id="cb1-7"></span>
<span id="cb1-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> url <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> meme_url_list:</span>
<span id="cb1-9">        variables <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sk.ContextVariables()</span>
<span id="cb1-10">        variables[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'prompt'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Why is this meme funny?"</span></span>
<span id="cb1-11">        variables[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'url'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> meme_base_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> url</span>
<span id="cb1-12">        meme <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">await</span> kernel.run_async(vision[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ApplyPromptToImage'</span>], input_vars<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>variables)</span>
<span id="cb1-13">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>meme<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)     </span></code></pre></div>
<p>Here are the results. The Vision API does a good job of understanding the image and generating a good explanation of why the meme is funny.</p>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Meme</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://www.meyerperin.com/images/meme2.png" class="img-fluid" width="300"></td>
<td>The humor in this meme comes from the irony and self-awareness of the situation. The person in the image is depicted as being awake at 3 AM, a time typically associated with sleep, while reading about the importance of sleep. The implication is that while they understand the value of sleep for health and well-being, they are not following this advice themselves. The relatable contradiction between what they’re doing (staying up late) and what they’re reading about (the importance of sleep) creates a humorous juxtaposition that many people can identify with, as it’s common for individuals to do things that go against their own better judgment or knowledge.</td>
</tr>
<tr class="even">
<td><img src="https://www.meyerperin.com/images/meme3.jpg" class="img-fluid" width="300"></td>
<td>This meme is humorous because it presents a situation where someone has comically circumvented a rule through a technicality. The text explains that while there’s a rule against having pumpkins in their dormitory, there’s no mention of pineapples. The images show a pineapple carved in a manner similar to a jack-o’-lantern, traditionally made from a pumpkin, often for Halloween. The humor arises from the person’s literal interpretation of the rules, exploiting the lack of specificity to create a loophole and do something in the spirit of what’s prohibited yet not technically against the rules. This kind of wit and playful rebellion against overly specific or seemingly arbitrary rules often resonates with people who enjoy clever ways to bend or skirt the rules without breaking them.</td>
</tr>
<tr class="odd">
<td><img src="https://www.meyerperin.com/images/meme1.jpg" class="img-fluid" width="300"></td>
<td>The humor in this meme arises from the juxtaposition of an inspirational saying typically found in areas of the home where food is prepared or consumed—like the kitchen—and placing it in a completely inappropriate context—the bathroom. Specifically, the framed quote says, “LIFE IS SHORT LICK THE BOWL,” which in a culinary context encourages people to enjoy life to the fullest, perhaps by savoring every last bit of their food. However, when placed in the bathroom, right next to a toilet bowl, the phrase takes on a literal and unpleasantly comical meaning. The idea of licking a toilet bowl is both absurd and humorous, evoking a reaction due to the drastic shift in the context of the phrase.</td>
</tr>
</tbody>
</table>
<p>In the next section, I’ll explain how to use the plugin to identify an animal in an image and pass the results to another function.</p>
</section>
<section id="chaining-the-plugin-answer-to-another-function" class="level1">
<h1>Chaining the plugin answer to another function</h1>
<p>In the example below, I first use the Vision plugin to identify an animal, and then use the results to ask for three interesting facts about an animal. I have createad a semantic function with the prompt <code>Provide three interesting and unusual facts about the animal {{$input}}</code> and called it <code>AnimalFacts</code>.</p>
<p>The URL I’m passing in the code below is a picture of an owl. The Vision API correctly identifies the animal as an owl, and the <code>AnimalFacts</code> function generates three interesting facts about owls.</p>
<p><img src="https://www.meyerperin.com/posts/https:/l.meyerperin.com/skv_owl.png" class="img-fluid"></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why do this in two steps?
</div>
</div>
<div class="callout-body-container callout-body">
<p>In my example, I’m doing two steps. First I’m using the GPT-4 Vision API in the call that identifies the animal from the image, and then GPT-3.5 in the call that generates the facts.</p>
<p>It would be possible to solve the problem with a single call to the Vision API, but it can be <a href="https://platform.openai.com/docs/guides/vision/calculating-costs">expensive</a>, so I get its results and pass it to a cheaper model for the text generation step.</p>
</div>
</div>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"></span>
<span id="cb2-2">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://l.meyerperin.com/skv_owl"</span></span>
<span id="cb2-3">gpt35 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAIChatCompletion(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-3.5-turbo"</span>, api_key, org_id)</span>
<span id="cb2-4">kernel.add_chat_service(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt35"</span>, gpt35)</span>
<span id="cb2-5"></span>
<span id="cb2-6">vision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel.import_skill(Vision())</span>
<span id="cb2-7">plugins <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel.import_semantic_skill_from_directory(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"."</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"plugins"</span>)</span>
<span id="cb2-8"></span>
<span id="cb2-9">variables <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sk.ContextVariables()</span>
<span id="cb2-10">variables[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'prompt'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What animal is this? Please respond in one word."</span></span>
<span id="cb2-11">variables[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'url'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> url</span>
<span id="cb2-12"></span>
<span id="cb2-13">animal <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">await</span> kernel.run_async(vision[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ApplyPromptToImage'</span>], input_vars<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>variables)</span>
<span id="cb2-14">facts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">await</span> kernel.run_async(plugins[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'AnimalFacts'</span>], input_str<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(animal))</span>
<span id="cb2-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"The animal from the picture is a </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>animal<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)  </span>
<span id="cb2-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>facts<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<p>From the call above, I got the following result about owls:</p>
<pre class="text"><code>1. Owls have specialized feathers with fringes of varying softness that help muffle 
sound when they fly. Their broad wings and light bodies also make them practically 
silent fliers, which helps them stalk prey more easily.

2. Unlike most birds, owls have both eyes facing forward which gives them better
 depth perception for hunting.

3. Some species of owls, such as the Great Gray Owl, can hear a mouse moving 
underneath a foot of snow from up to 60 feet away. Their ears are asymmetrical,
 with one ear being higher than the other, which helps them locate sounds in 
 multiple dimensions.</code></pre>
</section>
<section id="how-to-write-native-plugin-to-wrap-the-openai-api" class="level1">
<h1>How to write native plugin to wrap the OpenAI API</h1>
<p>In this section, I’ll explain all the steps involved in writing a Semantic Kernel native Python plugin to wrap the OpenAI API. I’ll use the <a href="https://beta.openai.com/docs/guides/vision">Vision API</a> as an example. The plugin code is in the <a href="https://github.com/lucas-a-meyer/sk-vision-py/blob/main/VisionPlugin.py">GitHub repository</a>.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dotenv <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dotenv</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb4-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> semantic_kernel.skill_definition <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> sk_function, sk_function_context_parameter</span>
<span id="cb4-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> semantic_kernel.orchestration.sk_context <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SKContext</span>
<span id="cb4-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span></code></pre></div>
<p>We need to import the OpenAI library, the SKContext class because our function has multiple parameters (the prompt and the image URL), and the decorators in <code>skill_definition</code> that will allow us to make the Python function visible to the semantic Kernel.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> Vision:</span>
<span id="cb5-2">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@sk_function</span>(</span>
<span id="cb5-3">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""Asks the GPT-4 Vision API to perform an operation described by the prompt</span></span>
<span id="cb5-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        on an image given its url"""</span>,</span>
<span id="cb5-5">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ApplyPromptToImage"</span></span>
<span id="cb5-6">    )</span>
<span id="cb5-7">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@sk_function_context_parameter</span>(</span>
<span id="cb5-8">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prompt"</span>,</span>
<span id="cb5-9">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The prompt you want to send to the Vision API"</span>,</span>
<span id="cb5-10">    )</span>
<span id="cb5-11">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@sk_function_context_parameter</span>(</span>
<span id="cb5-12">        name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"url"</span>,</span>
<span id="cb5-13">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>,</span>
<span id="cb5-14">    )</span></code></pre></div>
<p>The main code of the function consists in assembling a message that conforms to the <a href="https://beta.openai.com/docs/guides/vision">Vision API specification</a>. The message is then sent to the API, and the result is parsed and returned to the caller.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">        <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> ApplyPromptToImage(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, context: SKContext) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="cb6-2">        load_dotenv()</span>
<span id="cb6-3">        client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI(api_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OPENAI_API_KEY"</span>))</span>
<span id="cb6-4"></span>
<span id="cb6-5">        response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat.completions.create(</span>
<span id="cb6-6">        model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4-vision-preview"</span>,</span>
<span id="cb6-7">        messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb6-8">            {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: [</span>
<span id="cb6-9">                {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>context[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'prompt'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>},</span>
<span id="cb6-10">                {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"image_url"</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"image_url"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"url"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>context[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'url'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb6-11">            },},],}],</span>
<span id="cb6-12">        max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>,</span>
<span id="cb6-13">        )</span>
<span id="cb6-14"></span>
<span id="cb6-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> response.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message.content</span></code></pre></div>
<p>The full code for the plugin and associated demo can be found in the <a href="https://l.meyerperin.com/b_skvisionpy">GitHub repository</a>.</p>
</section>
<section id="have-i-ever-thought-about-creating-an-app-that-does-this-as-a-service" class="level1">
<h1>Have I ever thought about creating an app that does this as a service?</h1>
<p>Yes, and with the blog post above, you can easily create one yourself. It will probably take you less than an hour to get it working. The main challenge is to bill for it, as the Open AI Vision calls can get expensive very quickly.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-12-16-skv_py.html</guid>
  <pubDate>Tue, 26 Dec 2023 08:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/meme2.png" medium="image" type="image/png" height="121" width="144"/>
</item>
<item>
  <title>Badlands Ranch Dog Food Review</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-11-03-badlands_ranch.html</link>
  <description><![CDATA[ 



<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is a review of <a href="https://badlandsranch.com/">Badlands Ranch</a>, a dry dog food. I am not affiliated with the company in any way and I don’t receive any compensation for this review.</p>
</div>
</div>
<p>Our dog, TheFuzzy, is very picky with food. She will go into hunger strikes for an extended period of time if she dislikes the food. The first brand that worked reliably for us was <a href="../posts/2022-06-28-farmers-dog.html">The Farmer’s Dog</a>. The main drawback of that food is that it’s wet and frozen. It takes a fair amount of freezer space, the kids don’t like to handle it, it’s hard to travel with. We tried a few other brands, but none of them worked. Then we found <a href="https://badlandsranch.com/">Badlands Ranch</a>, a dry food funded by the actress Katherine Heigl, and decided to give it a try.</p>
<p>You can order the food on their <a href="https://www.badlandsranch.com">website</a>. They run promotions that give big discounts on the first order, but they seem to run promotions giving big discounts all the time.</p>
<section id="what-you-should-know" class="level2">
<h2 class="anchored" data-anchor-id="what-you-should-know">What you should know</h2>
<p>Here’s a few things that you should know before you try that are not obvious from the website:</p>
<ul>
<li>The <strong>packages are small</strong>, containing only 10 cups of food each. My dog is 40 lbs, and she needs 2.5 cups per day, so each package lasts only 4 days.</li>
<li>The food is <strong>expensive</strong>: if you buy the 6-bag bundle, it’s $203.70 for 60 cups, or $3.40 per cup. That’s $8.50 per day for my dog. Blue Buffalo food, a premium brand of wet food, is about $6.50 per day for my dog.</li>
</ul>
<p>However, my dog reliably likes it. Because it’s dry food, we can travel with it. It’s fairly calorie-dense, so it’s easy to carry a few days worth of food in a small bag. It’s also easy to store, and it doesn’t smell. The kids feed the dog without complaining, and the dog eats mostly without complaining, so it works well for us. Unless we’re eating pizza, in which case the dog will refuse to eat anything else. But you can’t blame her for that.</p>
</section>
<section id="promotions" class="level2">
<h2 class="anchored" data-anchor-id="promotions">Promotions</h2>
<p>Sometimes Badlands Ranch runs big promotions for large orders - I recently ordered 12 packages for $312.80. That’s $2.60 per cup, or $6.50 per day for my dog, same as Blue Buffalo. They send you a large (and annoying) number of emails, so you’ll know when they run promotions, even if you don’t really want to.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-11-03-badlands_ranch.html</guid>
  <pubDate>Fri, 03 Nov 2023 07:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/badlands.png" medium="image" type="image/png" height="85" width="144"/>
</item>
<item>
  <title>A Quick Tour of the Semantic Kernel</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-10-15-semantic_kernel.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The <a href="https://github.com/microsoft/semantic-kernel">Microsoft Semantic Kernel</a> is a thin, open-source, software development toolkit that makes it easier for applications to interact with AI services.</p>
<p>It was originally designed to power the Microsoft Copilots, such as Microsoft 365 and Bing. The initial version was in C#, but it has now been extended to Python and Java, and released to the developer community as an open-source package.</p>
<section id="python-code-for-this-post" class="level2">
<h2 class="anchored" data-anchor-id="python-code-for-this-post">Python code for this post</h2>
<p>The Python code for this post is <a href="https://links.meyerperin.com/sktour">available in a notebook on GitHub</a>.</p>
<p>In order to run the code of this post, you will need an <a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service">Azure subscription with access to the OpenAI API</a>, or an OpenAI subscription.</p>
<p>Although you can get a <a href="https://azure.microsoft.com/en-us/free/ai-services">free trial for Azure</a> that gives you many services, the OpenAI services in Azure are not free. You can see the prices <a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/">here</a>.</p>
</section>
<section id="differences-from-langchain" class="level2">
<h2 class="anchored" data-anchor-id="differences-from-langchain">Differences from LangChain</h2>
<ul>
<li>Semantic Kernel was designed to be more customizable than LangChain. It gives you more control but requires more coding.</li>
<li>Semantic Kernel was designed to help easily add LLM features to enterprise or large-scale consumer applications.</li>
<li>If you use Python, you can use both LangChain and Semantic Kernel.</li>
<li>If you use JavaScript, you can use LangChain, but not Semantic Kernel. There’s a community-supported TypeScript API for Semantic Kernel, but it’s not officially supported by Microsoft.</li>
<li>If you use Java or .NET, you can use Semantic Kernel, but not LangChain.</li>
</ul>
</section>
</section>
<section id="a-whirlwind-tour-through-semantic-kernel-in-python" class="level1">
<h1>A whirlwind tour through Semantic Kernel in Python</h1>
<p>In the post below, I’ll quickly show how to get started with Semantic Kernel in Python using an Azure subscription.</p>
<section id="the-kernel" class="level2">
<h2 class="anchored" data-anchor-id="the-kernel">The Kernel</h2>
<p>The Semantic Kernel is just a lightweight object where you will attach everything you need to complete your AI tasks.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> semantic_kernel <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sk</span>
<span id="cb1-2">kernel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sk.Kernel()</span></code></pre></div>
</section>
<section id="connectors" class="level2">
<h2 class="anchored" data-anchor-id="connectors">Connectors</h2>
<p>Connectors are the way you connect to AI services. You can connect multiple services to the same kernel, which allows you to perform a complex task using different services for each step.</p>
<p>For example, my subscription has two models deployed: one deployment named <code>gpt35</code> the GPT 3.5 Turbo model and one deployment named <code>gpt4</code> for a deployment of the GPT-4 model. I can load both of them into the kernel with the code below:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> semantic_kernel.connectors.ai.open_ai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AzureChatCompletion</span>
<span id="cb2-2"></span>
<span id="cb2-3">gpt35 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AzureChatCompletion(deployment_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt35"</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># yours may be different</span></span>
<span id="cb2-4">endpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>OPENAI_ENDPOINT,</span>
<span id="cb2-5">api_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>OPENAI_API_KEY)</span>
<span id="cb2-6"></span>
<span id="cb2-7">gpt4 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AzureChatCompletion(</span>
<span id="cb2-8">    deployment_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt4"</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># yours may be different</span></span>
<span id="cb2-9">endpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>OPENAI_ENDPOINT,</span>
<span id="cb2-10">api_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>OPENAI_API_KEY)</span>
<span id="cb2-11"></span>
<span id="cb2-12">kernel.add_chat_service(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt35"</span>, gpt35)</span>
<span id="cb2-13">kernel.add_chat_service(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt4"</span>, gpt4)</span></code></pre></div>
</section>
<section id="semantic-functions" class="level2">
<h2 class="anchored" data-anchor-id="semantic-functions">Semantic functions</h2>
<p>Semantic functions are functions that use large language models to perform a task. The simple example below shows how to create a semantic function that tells a knock-knock joke.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""knock, knock? Who’s there? </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">$input</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">. </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">$input</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> who?"""</span></span>
<span id="cb3-2"></span>
<span id="cb3-3">knock <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel.create_semantic_function(prompt, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>)</span>
<span id="cb3-4"></span>
<span id="cb3-5">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> knock(“Dishes<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">")</span></span>
<span id="cb3-6"><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">print</span>(response)</span></code></pre></div>
<p>The response will be something like <code>Dishes the police, open up!</code>.</p>
</section>
<section id="native-functions" class="level2">
<h2 class="anchored" data-anchor-id="native-functions">Native functions</h2>
<p>Native functions are regular Python functions. They can be used to perform any task that doesn’t require a large language model. For example, the code below classifies an image given a URL.</p>
<p>The function uses the <code>timm</code> library to download a pre-trained model and classify the image. The <code>@sk_function</code> decorator tags the following function <code>classify_image</code> as a function that can be imported by the Semantic Kernel.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> requests</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> PIL <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image</span>
<span id="cb4-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> timm</span>
<span id="cb4-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> timm.data.imagenet_info <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ImageNetInfo</span>
<span id="cb4-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> semantic_kernel.skill_definition <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> sk_function</span>
<span id="cb4-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> semantic_kernel.orchestration.sk_context <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SKContext</span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> ImageClassifierPlugin:</span>
<span id="cb4-9">&nbsp; &nbsp; <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb4-10">&nbsp; &nbsp; &nbsp; &nbsp; <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> timm.create_model(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"convnext_tiny.in12k_ft_in1k"</span>, pretrained<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-11">&nbsp; &nbsp; &nbsp; &nbsp; <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb4-12">&nbsp; &nbsp; &nbsp; &nbsp; data_config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> timm.data.resolve_model_data_config(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model)</span>
<span id="cb4-13">&nbsp; &nbsp; &nbsp; &nbsp; <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.transforms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> timm.data.create_transform(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>data_config, is_training<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb4-14">&nbsp; &nbsp; &nbsp; &nbsp; <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.imagenet_info <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ImageNetInfo()</span>
<span id="cb4-15"></span>
<span id="cb4-16">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@sk_function</span>(</span>
<span id="cb4-17">&nbsp; &nbsp; &nbsp; &nbsp; description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Takes a url as an input and classifies the image"</span>,</span>
<span id="cb4-18">&nbsp; &nbsp; &nbsp; &nbsp; name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classify_image"</span>,</span>
<span id="cb4-19">&nbsp; &nbsp; &nbsp; &nbsp; input_description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The url of the image to classify"</span>,</span>
<span id="cb4-20">    )</span>
<span id="cb4-21">&nbsp; &nbsp; <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> classify_image(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, url: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="cb4-22">&nbsp; &nbsp; &nbsp; &nbsp; image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.download_image(url)</span>
<span id="cb4-23">&nbsp; &nbsp; &nbsp; &nbsp; pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.transforms(image)[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>])</span>
<span id="cb4-24">&nbsp; &nbsp; &nbsp; &nbsp; cls <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.imagenet_info.index_to_description(pred.argmax())</span>
<span id="cb4-25">&nbsp; &nbsp; &nbsp; &nbsp; </span>
<span id="cb4-26">&nbsp; &nbsp; &nbsp; &nbsp; <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> cls.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">","</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-27">&nbsp; &nbsp; &nbsp; &nbsp; </span>
<span id="cb4-28">  &nbsp; <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> download_image(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, url):</span>
<span id="cb4-29">&nbsp; &nbsp; &nbsp; &nbsp; <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> Image.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(requests.get(url, stream<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).raw).convert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RGB"</span>)</span></code></pre></div>
<section id="loading-a-native-function-into-the-kernel" class="level3">
<h3 class="anchored" data-anchor-id="loading-a-native-function-into-the-kernel">Loading a native function into the kernel</h3>
<p>You can load native functions into the kernel with the <code>import_skill</code> method of the Kernel object.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">classify_plugin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel.import_skill(image_classifier, skill_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classify_image"</span>)</span></code></pre></div>
<p>The <code>classify_plugin</code> is a collection of functions. To call the <code>classify_image</code> function, you can use the code below:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">answer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classify_plugin.classify_image(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://links.meyerperin.com/tiger_jpg"</span>)</span>
<span id="cb6-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(answer)</span></code></pre></div>
<p>For example, if I use the URL below as the parameter:</p>
<p><code>https://links.meyerperin.com/tiger_jpg</code></p>
<p><img src="https://www.meyerperin.com/posts/http:/2.bp.blogspot.com/-tG6z7DOsHNc/T6Z1DuzXs9I/AAAAAAAAGfY/YTmFDxw0Qxg/s320/animal+pictures+%252812%2529.jpg" class="img-fluid"></p>
<p>The answer will be <code>tiger</code>.</p>
</section>
</section>
</section>
<section id="plug-ins" class="level1">
<h1>Plug-ins</h1>
<p>One of the greatest strengths of the Microsoft Semantic Kernel is the ability of creating plugins. Plugins are collections of functions that can be imported into the kernel.</p>
<p>A semantic plugin is a collection of semantic functions. Each function should be in its own directory. Each directory should have two files: <code>config.json</code> and <code>skprompt.txt</code>.</p>
<p>The <code>config.json</code> file contains the configuration of the semantic function: which is the preferred engine to use, the temperature, etc.</p>
<p>The <code>skprompt.txt</code> file contains the prompt of the semantic function. The prompt is the text that will be sent to the engine to generate the response.</p>
<section id="example-directory-structure" class="level2">
<h2 class="anchored" data-anchor-id="example-directory-structure">Example directory structure</h2>
<pre><code>└───plugins
    └───jokes
        ├───cross_the_road_joke
        |   ├───config.json
        |   └───skprompt.txt
        └───knock_knock_joke
            ├───config.json
            └───skprompt.txt</code></pre>
</section>
<section id="an-example-config.json-file" class="level2">
<h2 class="anchored" data-anchor-id="an-example-config.json-file">An example config.json file</h2>
<p>The configuration file below shows a possible configuration for a semantic function that generates knock-knock jokes. The <code>default_services</code> property is an array of the preferred engines to use. The <code>completion</code> property contains the parameters that will be sent to the engine. The <code>input</code> property contains the parameters that will be sent to the semantic function.</p>
<p>I frequently use the <code>default_services</code> property to send simple tasks to cheaper services like GPT-3.5 and more complex tasks to more expensive services like GPT-4.</p>
<p>The <code>description</code> field is important, because it can be used by the <code>Planner</code> function of the kernel, if you want to let the kernel itself select which functions to call.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"schema"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"type"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"completion"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-4">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Generates a knock-knock joke based on user input"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"default_services"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt35"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-6">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"completion"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-7">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"temperature"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-8">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"number_of_responses"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-9">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"top_p"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-10">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"max_tokens"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4000</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-11">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"presence_penalty"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-12">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"frequency_penalty"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span></span>
<span id="cb8-13">       <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb8-14">       <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"input"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-15">     <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"parameters"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-16">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"name"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-17">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"description"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The topic that the joke should be written about"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-18">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"defaultValue"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dishes"</span></span>
<span id="cb8-19">     <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb8-20">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-21"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</section>
<section id="an-example-skprompt.txt-file" class="level2">
<h2 class="anchored" data-anchor-id="an-example-skprompt.txt-file">An example skprompt.txt file</h2>
<p>The prompt below is the prompt for the semantic function that generates knock-knock jokes. The <code>{{$input}}</code> placeholder will be replaced by the value of the <code>input</code> parameter.</p>
<pre class="text"><code>knock, knock? 
Who's there? 
{{$input}}. 
{{$input}} who?


Repeat the whole setup and finish the joke.</code></pre>
</section>
<section id="loading-the-plugin-into-the-kernel" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-plugin-into-the-kernel">Loading the plugin into the kernel</h2>
<p>You can load all the functions that are inside a plugin directory with the <code>import_semantic_skill_from_directory</code> method of the kernel object.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">jokes_plugin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel.import_semantic_skill_from_directory(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"plugins"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"jokes"</span>)</span></code></pre></div>
<p>The resulting object is a dictionary of functions. You can load the functions into variables or call them directly.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">knock <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> jokes_plugin[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"knock_knock_joke"</span>]</span>
<span id="cb11-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span> (knock(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Dishes"</span>))</span>
<span id="cb11-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dishes the police, open up!</span></span>
<span id="cb11-4"></span>
<span id="cb11-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(jokes_plugin[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cross_the_road_joke"</span>](<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Tiger"</span>))</span>
<span id="cb11-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Why did the tiger cross the road? To show the chicken it can be done.</span></span></code></pre></div>
</section>
</section>
<section id="calling-multiple-functions-in-sequence" class="level1">
<h1>Calling multiple functions in sequence</h1>
<p>As you saw before, we loaded the native function classify_image into the kernel. And in the block above, we loaded the jokes plugin into the kernel. We can call both functions in sequence with the code below:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">context <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kernel.create_new_context()</span>
<span id="cb12-2">context[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> url</span>
<span id="cb12-3"></span>
<span id="cb12-4">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">await</span> kernel.run_async(</span>
<span id="cb12-5">    classify_plugin[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classify_image"</span>],</span>
<span id="cb12-6">    jokes_plugin[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cross_the_road_joke"</span>],</span>
<span id="cb12-7">    input_context<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>context</span>
<span id="cb12-8">)</span>
<span id="cb12-9"></span>
<span id="cb12-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(response)</span></code></pre></div>
<p>This code will call the first (native) function that classifies an image, and then call the second (semantic) function that generates a joke about the image. Since we loaded the image of a tiger, the response will be something like:</p>
<p><code>Why did the tiger cross the road? To show the chicken it could be done.</code></p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>I hope this brief tour helps you get started. If you want to learn more, you can check the <a href="https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide/getting-started?tabs=python">official documentation</a>.</p>
<p>You can also join the community <a href="https://aka.ms/SKDiscord">Discord server</a>.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-10-15-semantic_kernel.html</guid>
  <pubDate>Sun, 15 Oct 2023 07:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/tiger.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Getting Started with Midjourney</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-09-23-midjourney.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level1">
<h1>Introduction</h1>
<p><a href="https://www.midjourney.com/">Midjourney</a> is a generative AI tool that can generate high quality images from text prompts. It is particularly good at generating photorealistic images, and also good at blending an existing picture with a prompt. Lots of people use Midjourney as a digital diary, or to quickly create images for their social media and blog posts.</p>
<p>One unique characteristic of Midjourney is that its interface is only available on <a href="https://discord.com/">Discord</a>, a popular chat app. In order to create images, you have to chat with the Midjourney bot on a Discord server.</p>
<p>This is a tutorial on how to get started with Midjourney. While it’s mostly based on the <a href="https://docs.midjourney.com/docs/quick-start">official Midjourney getting started guide</a>, I have added a few suggestions that made my life much easier, especially my Step 2. Hopefully will help you, too.</p>
</section>
<section id="installing-midjourney" class="level1">
<h1>Installing Midjourney</h1>
<section id="step-1-log-in-to-discord" class="level2">
<h2 class="anchored" data-anchor-id="step-1-log-in-to-discord">Step 1: Log in to Discord</h2>
<p>If you don’t have a Discord account, you will have to <a href="https://support.discord.com/hc/en-us/articles/360033931551-Getting-Started">create one</a>. Discord has apps for all major operating systems, mobile devices, and also a web app. Install all apps you think you’re going to use. I frequently use the desktop app the most, but the mobile app is also very convenient and works surprisingly well for chatting with the Midjourney bot.</p>
</section>
<section id="step-2-an-easier-way-create-your-own-server" class="level2">
<h2 class="anchored" data-anchor-id="step-2-an-easier-way-create-your-own-server">Step 2: An easier way: create your own server</h2>
<p>This is where my instructions are <strong>very different</strong> from the official guide. The official guide asks you to join the <a href="https://discord.gg/2YJYJQ6Z">Midjourney Discord server</a> and chat with the Midjourney bot there. I don’t recommend doing that. The Midjourney Discord server is very active and noisy, and you will get <strong>a lot</strong> of notifications from other people’s conversations. It’s also very easy to get lost in the sea of messages. You can work around that by <a href="https://docs.midjourney.com/docs/direct-messages">directly messaging the Midjourney bot</a>, but you will still have to configure the server settings to mute all channels and notifications.</p>
<p>Although it may sound intimidating, creating your own server is very easy and it’s mostly click-based. You can create a server for free, and you can create as many servers as you want. You can see detailed instructions <a href="https://support.discord.com/hc/en-us/articles/204849977-How-do-I-create-a-server-">here</a>. Here’s a quick summary:</p>
<section id="click-the-button-on-the-left-sidebar-to-add-a-server" class="level3">
<h3 class="anchored" data-anchor-id="click-the-button-on-the-left-sidebar-to-add-a-server">1. Click the <code>+</code> button on the left sidebar to <code>Add a Server</code></h3>
<p><img src="https://www.meyerperin.com/posts/https:/support.discord.com/hc/article_attachments/360058897831/Screen_Shot_2020-06-04_at_1.11.06_PM.png" class="img-fluid"></p>
</section>
<section id="select-create-a-server" class="level3">
<h3 class="anchored" data-anchor-id="select-create-a-server">2. Select <code>Create a server</code></h3>
<p><img src="https://www.meyerperin.com/posts/https:/support.discord.com/hc/article_attachments/360058273791/Capture.JPG" class="img-fluid"></p>
</section>
<section id="give-your-server-a-name-and-optionally-an-icon-and-click-create" class="level3">
<h3 class="anchored" data-anchor-id="give-your-server-a-name-and-optionally-an-icon-and-click-create">3. Give your server a name and optionally an icon, and click <code>Create</code></h3>
<p><img src="https://www.meyerperin.com/posts/https:/support.discord.com/hc/article_attachments/360058897871/Screen_Shot_2020-06-04_at_1.40.12_PM.png" class="img-fluid"></p>
</section>
<section id="thats-it" class="level3">
<h3 class="anchored" data-anchor-id="thats-it">4. That’s it!</h3>
<p>You have created your own server. Now you need to subscribe to Midjourney and invite the Midjourney bot to your server.</p>
</section>
</section>
<section id="step-3-subscribe-to-midjourney" class="level2">
<h2 class="anchored" data-anchor-id="step-3-subscribe-to-midjourney">Step 3: Subscribe to Midjourney</h2>
<p>This is the hard part. There are no free trials anymore, and you need a paid subscription in order to use Midjourney.</p>
<ul>
<li>Visit <a href="https://midjourney.com/account">Midjourney.com/account</a>.</li>
<li>Sign in using your <strong>verified</strong> Discord account.</li>
<li>Select a subscription tier and click <code>Subscribe</code>.</li>
</ul>
<p>The least expensive subscription is good for most purposes, and I suggest you use that one to get started. This will give you about three hours of server time per month, and you lose what you don’t use. Even though I use Midjourney a lot, I rarely use up all my server time. You <strong>can</strong> top off if you need.</p>
<p><img src="https://www.meyerperin.com/posts/https:/cdn.document360.io/3040c2b6-fead-4744-a3a9-d56d621c6c7e/Images/Documentation/MJ_SubscriptionTiers.png" class="img-fluid"></p>
</section>
<section id="step-4-invite-the-midjourney-bot-to-your-server" class="level2">
<h2 class="anchored" data-anchor-id="step-4-invite-the-midjourney-bot-to-your-server">Step 4: Invite the Midjourney bot to your server</h2>
<p>Now that you have a server and a subscription, you need to invite the Midjourney bot to your server. This is also very easy, and done mostly by clicking.</p>
<ol type="1">
<li><p>In the left sidebar, right-click your server and select <code>App catalog</code> <img src="https://www.meyerperin.com/images/MJ-1.png" class="img-fluid"></p></li>
<li><p>Search for <code>Midjourney</code>, select <code>Midjourney Bot</code>, and click <code>Add to server</code> <img src="https://www.meyerperin.com/images/MJ-2.png" class="img-fluid"></p></li>
</ol>
<p><img src="https://www.meyerperin.com/images/MJ-3.png" class="img-fluid"></p>
<ol start="3" type="1">
<li>Select your server from the dropdown, and click <code>Continue</code>, and then <code>Authorize</code>. <img src="https://www.meyerperin.com/images/MJ-4.png" class="img-fluid"></li>
</ol>
<p>You can now start using Midjourney in your own.</p>
</section>
</section>
<section id="basic-usage-of-midjourney" class="level1">
<h1>Basic usage of Midjourney</h1>
<p>Now that Midjourney is installed on your server, you can start using it. I just send direct messages to it by right-clicking it and selecting <code>Message</code>.</p>
<p><img src="https://www.meyerperin.com/images/MJ-5.png" class="img-fluid"></p>
<p>The official guide has a <a href="https://docs.midjourney.com/docs/quick-start">very good introduction</a> to the basic usage of Midjourney, starting on step 5. I will just summarize the main command <code>imagine</code> here, and show you an example of how you can use your own image as a starting point.</p>
<section id="the-imagine-command" class="level2">
<h2 class="anchored" data-anchor-id="the-imagine-command">The <code>imagine</code> command</h2>
<p>The <code>imagine</code> command is the main command you will use to generate images. It takes a prompt as input, and generates an image based on the prompt. The prompt can be a few words, a sentence, or even a paragraph. The longer the prompt, the more specific the image will be.</p>
<p>There are a lot of prompting techniques, and I will not go into details here. You can find a lot of examples in the <a href="https://docs.midjourney.com/docs/explore-prompting">official guide</a>.</p>
<p>Here’s a quick example:</p>
<p><code>/imagine standard schnauzer sleeping on a computer keyboard</code></p>
<p>Midjourney by default will reply with four suggestions. Their numbers start on the top left and go clockwise. There will be some buttons under the suggestions, labeled U1, U2, U3, U4 and V1, V2, V3, V4.</p>
<p>You can click on the U buttons to upscale (increase the resolution) of a picture you liked, and click on the V buttons to see more variations of the current suggestion. If you’re going to use the image for social media, I suggest you upscale it before downloading.</p>
<p>There’s also a button to regenerate all images if you don’t like any of the suggestions. Here’s what I got:</p>
<p><img src="https://www.meyerperin.com/images/MJ-6.png" class="img-fluid"></p>
<p>I like the second one, so I clicked on the U2 button to upscale it. Then I clicked on the download button to download the image. Here’s the final result:</p>
<p><img src="https://www.meyerperin.com/images/MJ-7.png" class="img-fluid"></p>
</section>
<section id="using-an-existing-image" class="level2">
<h2 class="anchored" data-anchor-id="using-an-existing-image">Using an existing image</h2>
<p>You can use an existing image with the <code>/imagine</code> command. I frequently use my own headshot and ask Midjourney to put me in some weird place or situation. In order for Midjourney to use your image, you need to upload it to the web first and give Midjourney the URL. I have my own server, but you can also upload your image to Discord and use the URL Discord gives you, or upload it to GitHub. There are plenty of other services you can use, too, like <a href="https://imgur.com/">Imgur</a>.</p>
<p>My headshot is at <code>https://links.meyerperin.com/headshot</code>.</p>
<p><img src="https://www.meyerperin.com/images/lucas_new_headshot.png" class="img-fluid"></p>
<p>I can use it with the <code>/imagine</code> command like this:</p>
<p><code>/imagine https://links.meyerperin.com/headshot as Batman in Gotham City</code></p>
<p>And here is the final result:</p>
<p><img src="https://www.meyerperin.com/images/another-lucas-batman.png" class="img-fluid"></p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>I hope this tutorial helped you get started with Midjourney. If you have any questions, please feel free to drop me a message using my socials above (LinkedIn and Threads are my preferred ones).</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-09-23-midjourney.html</guid>
  <pubDate>Sat, 23 Sep 2023 07:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/lucas_batman.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Getting started with Midjourney</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-09-22-getting-started-with-midjourney.html</link>
  <description><![CDATA[ 



<p>I’ve added a new section to my blog, called <a href="https://links.meyerperin.com/mj">A Quick Tour of Midjourney</a>.</p>
<p>You can find it here: <a href="https://links.meyerperin.com/mj" class="uri">https://links.meyerperin.com/mj</a>.</p>
<p>If you never used Midjourney before, or if you tried to use it but got quickly intimidated by the volume of messages in their Discord server, this will probably help.</p>
<p>An important note: Midjourney is now a paid service, so you have to pay for a subscription (currently $10/month) to use it. There are no trials anymore.</p>



 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-09-22-getting-started-with-midjourney.html</guid>
  <pubDate>Fri, 22 Sep 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/lucas-mj.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Father’s Day 2023</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-06-18-fathers-day.html</link>
  <description><![CDATA[ 



<p>I didn’t have a good father. But my mother showed up. Happy Father’s Day to all fathers that show up, and to all non-dads and single moms that do so much every day to fill in that giant void.</p>
<p>We are different in social media than we are in real life. The most important thing I am is a father, but I avoid talking about my family on social media.</p>
<p>I’ll make a small exception today to share the “All About My Dad” worksheet my kids filled for me:</p>
<p>Dad’s favorite thing to do: spend time with us Dad’s favorite food: eggs benedict Dad’s job: data scientist that does good Dad is happy when: he spends time with us, gets kisses from the dog Dad is mad when: we don’t do our homework and don’t ask for help Dad is really good at: being a dad, picking up dog poop Dad likes to say: “It’s Broncos country, let’s ride” (I’m a Seahawks fan) I love my dad because: he is good at math, he is caring and loving, he’s funny My dad loves me because: I’m the best (older, middle, youngest) child</p>
<p>I’m very lucky, and I hope you are too. It goes faster than it seems.</p>



 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-06-18-fathers-day.html</guid>
  <pubDate>Sun, 18 Jun 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/calvin-father.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>A/B testing needs a theory</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-06-11-ab-tests.html</link>
  <description><![CDATA[ 



<p>Randomized controlled experiments (A/B tests) are frequently said to be the gold standard for decision-making. However, to make a good decision, you have to really understand what question is being answered.</p>
<p>Let’s say, hypothetically, that you want to try a new color palette for your website. You have the mechanisms to run proper A/B tests: you can bucket users into A and B groups such that the only difference between them is the color palette. You choose, arbitrarily, a random palette, run the experiment for a week, and find that the users in the B group have a $200k lift in revenue, which annualized represents a $10M increase in revenue. That’s not nothing. You roll it out to all users, write your performance review, book a party and wait for your promotion.</p>
<p>There’s just one important thing missing: you have no idea exactly why it worked. Here’s a few possible explanations, some of which are quite far-fetched:</p>
<ul>
<li><p>Maybe the new palette just randomly made your site look more like its main competitor, and users that would normally leave your site keep using it, blissfully unaware. The next time your competitor changes their color schema, these users will not be confused anymore and will leave. And maybe they’ll do this next week, because they just realized they lost some users.</p></li>
<li><p>Maybe the color palette of the world outside makes your new palette very attractive, but only for the season when the test ran, but it makes it less attractive in other seasons of the year. With the change you’re actually losing money for the year. That’s a little bit of a joke explanation, but it has a strong scientific basis (the “crocs and socks illusion”, also the “dress illusion”).</p></li>
<li><p>Maybe you found a cheat code, the exact combination of colors that makes other people understand you better, and could use this to improve educational outcomes and save the whole world $1T per year, rather than $200k for that week. By deploying it to your site and moving on, you have a lost opportunity cost of approximately $1T.</p></li>
<li><p>Maybe you really found something that only makes it easier for users to use your site and that it’s going to work well for one year or more, so it’s really valued at $10M per year… as long as you don’t make any other changes to the site.</p></li>
</ul>
<p>Your A/B experiment is on the top of the evidence pyramid, but for which of the cases above? Without a theory and alternative explanations, you may never know.</p>
<p>There is, however, a hint that you learned something, and that it’s familiar to data scientists: the descriptive, predictive and prescriptive/causal framework. When you really understand how something works, if you have the resources, you can make it happen at will. For example, if the reason why you got a lift in your experiment is because you were looking like your much larger competitor, you could now mimic their color palette every time they make a change and keep getting the lift. You could mimic palettes of other larger competitors and get lifts there, too.</p>
<p>A/B tests are great evidence when you understand the question. Better make sure you do.</p>



 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-06-11-ab-tests.html</guid>
  <pubDate>Tue, 13 Jun 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/schnauzer_scientist.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>You should not base your career plan on mine</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-05-31-you-should-not-base-your-career-plan-on-mine.html</link>
  <description><![CDATA[ 



<p>I started writing code when I was 9 years old. I ended up going to Law school. Maybe you should not follow my career path.</p>
<section id="early-promises" class="level2">
<h2 class="anchored" data-anchor-id="early-promises">Early promises</h2>
<p>I was never a great student. I got easily distracted. I could do extremely well if the subject interested me, but it frequently did not. Sometimes, some aspect of a subject interested me much more than what the academic program wanted from students. For example, when we were studying the expansion of the Portuguese and Spanish in the 1500s, I really wanted to understand the science of sailing. My teacher wanted me to memorize dates. My saving grace was that I did well in tests, especially standardized tests. And in the country I’m from, Brazil, you can get into a good university if you do well in standardized tests.</p>
</section>
<section id="family-matters" class="level2">
<h2 class="anchored" data-anchor-id="family-matters">Family matters</h2>
<p>Realizing that, my family decided I was going to be a medical doctor. Back then, it was a pathway to riches in Brazil. My family’s thinking went like this: most people that want to be doctors can’t because they can’t get into medical school. Since presumably I could pass the test and get in, I got that idea drilled into me from a young age. I was going to be a doctor.</p>
<p>In a comic twist of fate, people in my family started fighting over an inheritance that was not very big (maybe equivalent to $100k USD today). People started getting divorced. They needed lawyers. The campaign to make me a lawyer started.</p>
<p>Ultimately, when I was 17, I needed to decide what career to pursue. I actually applied for Law, Medicine, and Engineering in the three top universities from my state. Maybe fate would decide where I was going to go. Fate had other plans: I got into all three. One of my friends wanted to be a lawyer, so I followed him.</p>
</section>
<section id="law-school" class="level2">
<h2 class="anchored" data-anchor-id="law-school">Law school</h2>
<p>I hated law school. Not the school itself, but who I thought I needed to become in order to be a successful lawyer in Brazil in the early 2000s. At some point in the second year, we were asked to do a subject completely outside of Law. I took long to find one and only had slim pickings. I ended up doing Assembly programming. Not only did I love it, but I did super well. I quit Law school, did the standardized tests again, and got into Computer Science.</p>
<p>I kept having the same problems I have always had as a student: in Computer Science, I was interested in databases, graph theory, and statistics, but not in compilers or linear algebra. I really loved abstract algebra and proofs, operating systems, and programming languages, but hated computer architecture. Again, not a great student, with some bright spots, enough to graduate.</p>
</section>
<section id="happily-ever-after" class="level2">
<h2 class="anchored" data-anchor-id="happily-ever-after">Happily ever after?</h2>
<p>You’d think this was the end of the story, but when I graduated, I found that it was very hard to find a job as a computer scientist in Brazil. I ended up working in Technical Sales, and I really did not like it, mostly because of the way the incentives for my position were set up. So I made a plan to move to the US. My company needed people to work in Finance, so I learned Finance and transferred to the US. When I could, I would transfer back to software engineering.</p>
</section>
<section id="not-that-easy" class="level2">
<h2 class="anchored" data-anchor-id="not-that-easy">Not that easy</h2>
<p>It turns out that transferring from Finance into software engineering was not easy. First, I needed to wait several years because of immigration restrictions. By the time I could change job families, I had been out of Computer Science school for a while. Interviews were today’s equivalent of Leetcode, but I had no practice. Also, I started to really like Finance: I was good at it. I went back to school to learn more Finance and get really, really good at it. At some point, I started thinking that going back into a software engineering position would not make me happy: I would have to go back a lot in my career to start again.</p>
<p>I lucked out. Suddenly, there was this new thing called Data Science that required technical skills, statistics, and expertise in a subject-matter. Given my background, I could claim to have an expertise in Finance. Even though my department didn’t have a data science career, I started doing a lot of data science.</p>
</section>
<section id="you-are-what-your-numbers-say-you-are" class="level2">
<h2 class="anchored" data-anchor-id="you-are-what-your-numbers-say-you-are">You are what your numbers say you are</h2>
<p>In American football, there’s this saying: “You are what your numbers say you are.” Even though I had worked in Finance for a decade and built some cool models where the Finance was the feature, not the tech, everybody saw me as a “tech person”. One day, I was in my kitchen talking to my sister-in-law, who works in Finance and had only known me as somebody who worked in Finance. At some point, she called me “a tech person”. It was then that I decided to embrace it. I started working hard to convert my position from Finance to engineering. At this point, I was lucky to have a visionary manager that supported that and enabled me (and I hope both of us) to be very successful.</p>
</section>
<section id="ikigai" class="level2">
<h2 class="anchored" data-anchor-id="ikigai">Ikigai</h2>
<p>The Japanese have a principle of career happiness called Ikigai: the best career is at the midpoint between four things: what you are good at, what the world needs, what can get you paid, and what makes you happy. For a decade, I had thought that going back to engineering would be a problem for either getting paid or making me happy, and I settled for being happy with Finance. It turns out that I could do a lot with Data Science, whether it was related to Finance or not. I ended up doing a lot of fun Data Science projects that I’m very proud of.</p>
<p>At this point in my career, I hired a career coach. I wish I had done that a lot sooner. She helped me document what was important to me. It was also during a period where the Data Science market was super hot and I had lots of competing offers (those were the days…). Knowing a little bit more about the impact I wanted to have in the world while still providing for the needs of my family helped me think about what I would love to have in a position. Again, I lucked out - among several competing offers, an old friend reached out with an opportunity that was a perfect fit for me.</p>
</section>
<section id="the-end-of-the-beginning" class="level2">
<h2 class="anchored" data-anchor-id="the-end-of-the-beginning">The end of the beginning</h2>
<p>While I lucked out in some points of my career, I also had my share of bad luck. For one, immigration restrictions held me back. Sometimes, reorgs at work required me to prove myself all over again. Some personal things made me realize that you never know what someone is going through in life. You only see a small facet of what they choose to let on.</p>
<p>But maybe this whole experience was worthwhile. I’ve been exposed to a lot of things, and I have a great opportunity to help the world be a better place through my work. I’m not sure I would have gotten here if I had followed a more traditional path. In any case, it doesn’t matter. What matters is that I’m here now and that I can do it now.</p>
</section>
<section id="what-about-you" class="level2">
<h2 class="anchored" data-anchor-id="what-about-you">What about you?</h2>
<p>I don’t know what your Ikigai is. I know that sometimes you can get far off-path. I needed help to find my bearings. You shouldn’t follow my career path, as I was lost for a long time. But you can learn from my mistakes, and learn what you’re good at and what makes you happy sooner rather than later, and start driving towards that. I hope your road to happiness is shorter than mine, and that it has at least as many beautiful sights along the way.</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-05-31-you-should-not-base-your-career-plan-on-mine.html</guid>
  <pubDate>Wed, 31 May 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/schnauzer_banker.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Happy Towel Day!</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-05-25-happy-towel-day.html</link>
  <description><![CDATA[ 



<p>Happy Towel Day for those who celebrate it! On this day, fans of the famous Douglas Adams’ book Hitchhikers Guide to the Galaxy carry a towel with them everywhere. Why? Because, as the Guide says, a towel is the most massively useful thing an interstellar hitchhiker can have. As a tribute to the book, I decided to write a blog post about the number 42, which is the answer to the ultimate question of life, the universe, and everything.</p>
<section id="the-answer-to-the-ultimate-question-of-life-the-universe-and-everything" class="level2">
<h2 class="anchored" data-anchor-id="the-answer-to-the-ultimate-question-of-life-the-universe-and-everything">The Answer to the Ultimate Question of Life, the Universe, and Everything</h2>
<p>In the Hitchhikers Guide to the Galaxy, a supercomputer named Deep Thought is asked to calculate the answer to the ultimate question of life, the universe, and everything. After seven and a half million years, Deep Thought returns with the answer: forty-two. Although there are many theories about why the number came to be (101010 in binary, the angle at which light refracts through water to create a rainbow, etc.), the truth is that Douglas Adams chose the number randomly.</p>
<p>In his words: “The answer to this is very simple. It was a joke. It had to be a number, an ordinary, smallish number, and I chose that one. Binary representations, base thirteen, Tibetan monks are all complete nonsense. I sat at my desk, stared into the garden and thought ‘42 will do’ I typed it out. End of story.”</p>
</section>
<section id="forty-two-in-literature" class="level2">
<h2 class="anchored" data-anchor-id="forty-two-in-literature">Forty-Two in Literature</h2>
<p>Perhaps, subconsciously, Adams chose the number forty-two because of its significance in the works of another author that is also known for his use of humor and wit, and also admired by scientists, especially mathematicians. Lewis Carroll, the writer of Alice in Wonderland, made repeated use of the number 42 in his writings. The original version of Alice in Wonderland had 42 illustrations, and the king also makes use of rule 42, stating that all persons more than a mile high must leave the court immediately. His poem, the Hunting of the Snark, also has a rule 42 (no one shall speak to the man at the helm).</p>
<p>The number 42 also appeared in Doctor Who, Star Trek, and The X-Files. Once the number made its way into literature and other media liked by scientists, it would not take long until it was used in computer science.</p>
</section>
<section id="the-significance-of-forty-two-in-computer-science" class="level2">
<h2 class="anchored" data-anchor-id="the-significance-of-forty-two-in-computer-science">The Significance of Forty-Two in Computer Science</h2>
<p>Generating random numbers is a common task in computer science. One way to generate random numbers is to use a seed, which is a number that is used to initialize a pseudorandom number generator. The same seed will always produce the same sequence of numbers. Using a seed allows for reproducibility, which is important for debugging and testing.</p>
<p>In 2016, the software engineer Aleksey Bilogur published a blog post analyzing GitHub and searching for the most used random seeds. The results: 0 was the most used seed, with 40% of the results, with 42 coming in second with 17.3% of the results, followed by 1 with 16.8%, 1234 with 4.14%, and 123 with 1.75%.</p>
</section>
<section id="do-you-like-wikipedia" class="level2">
<h2 class="anchored" data-anchor-id="do-you-like-wikipedia">Do you like Wikipedia?</h2>
<p>In the book, the Guide is a competitor to the Encyclopedia Galactica, which is a repository of all knowledge in the universe. The Guide, instead of being written by experts, can comically be edited by anyone. The big advantage of the Guide, which accounts for most of its success, is that it’s slightly cheaper. Presciently, that is similar to the way Wikipedia works.</p>
<p>Therefore, on this Towel Day, I am donating $42 to Wikipedia, which my employer generously matches.</p>
<p>Happy Towel Day!</p>


</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-05-25-happy-towel-day.html</guid>
  <pubDate>Thu, 25 May 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/42.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Google Duplex was going to change the world five years ago</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-05-24-google-duplex-was-going-to-change-the-world-five-years-ago.html</link>
  <description><![CDATA[ 



<section id="google-duplex-was-going-to-change-the-world-five-years-ago" class="level1">
<h1>Google Duplex was going to change the world five years ago</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In 2018, Google announced its artificial intelligence (AI) system called Google Duplex, which was designed to make phone calls on behalf of users for tasks such as booking haircut appointments or making restaurant reservations. The technology sparked both excitement and concern, as people worried about the potential implications of AI taking over jobs and being used for social engineering purposes.</p>
</section>
<section id="the-reality-of-google-duplex" class="level2">
<h2 class="anchored" data-anchor-id="the-reality-of-google-duplex">The Reality of Google Duplex</h2>
<p>As with many new technologies, the initial hype surrounding Google Duplex has given way to a more nuanced understanding of its capabilities and limitations. One user review revealed that the actual experience of using Duplex was less than ideal, as it took longer to set up the AI system to make a call than it would have taken to simply make the call themselves. Google later admitted that at least 25% of calls made by Duplex failed and required human intervention, highlighting the limitations of the technology. Furthermore, the COVID-19 pandemic has significantly reduced the need for booking services. Dropping my kid at a high school in 2022 quickly confirmed to me that haircuts were not a priority.</p>
</section>
<section id="duplexs-integration-and-current-state" class="level2">
<h2 class="anchored" data-anchor-id="duplexs-integration-and-current-state">Duplex’s Integration and Current State</h2>
<p>Google Duplex has since been integrated into Pixel smartphones and the Google Assistant, allowing users to access the AI system more easily. However, user reviews on platforms like Reddit have been mixed, with many expressing the sentiment that Duplex is “great when it works.” A few people have mentioned that they have had success using Duplex to make restaurant reservations, but not all restaurants accept it.</p>
</section>
<section id="large-language-models-and-the-future" class="level2">
<h2 class="anchored" data-anchor-id="large-language-models-and-the-future">Large Language Models and the Future</h2>
<p>When Duplex was demonstrated by Google’s CEO in 2018, it seemed ready to take over the world. It’s a good reminder that demonstrations are usually very scripted and tested, and that may give the impression that things work a lot better than they would work in the real world.</p>
<p>This is also a good reminder to take a lot of what you see about Large Language Models with a grain of salt. LLMs can do amazing things, but they are not perfect, and in many cases, they are still very imperfect. Emerging technologies like chaining and goal-seeking could significantly improve the capabilities of systems based in language models, allowing them to better understand and improve automatically, but most products I see on my day-to-day are just thin wrappers on top of an existing model like ChatGPT, with minimal engineering. I don’t think GPT is going to kill engineering. I’m entirely on the opposite side of the spectrum: I think it’s going to make engineering more important than ever. Somebody will need to integrate and monitor these models and their applications, and that’s not going to be a trivial task.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>If you see the pace of AI technology releases releases and you get caught up in the hype, you may be worried like the people were worried about Duplex in 2018. Take your time to learn about new technologies. Be intentional: it’s definitely worthwhile understanding what LLMs are and are their advantages and limitations, but not necessarily optimal worrying about every new application, like AutoGPT. Remember the Vicki Boykis rule: whatever is important will be here six months from now, a lot will not.</p>


</section>
</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-05-24-google-duplex-was-going-to-change-the-world-five-years-ago.html</guid>
  <pubDate>Wed, 24 May 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/schnauzer_haircut.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>My Experience Using Large Language Models to Write Blog Posts</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-05-23-my-experience-using-large-language-models-to-write-blog-posts.html</link>
  <description><![CDATA[ 



<section id="my-experience-using-large-language-models-to-write-blog-posts" class="level1">
<h1>My Experience Using Large Language Models to Write Blog Posts</h1>
<p>I recently conducted an experiment using large language models (LLMs) to write blog posts. However, I didn’t enjoy the experience as much as I thought I would, even though LLMs should have been helpful since English is not my first language.</p>
<section id="the-problems-of-using-llms-to-write-for-you" class="level2">
<h2 class="anchored" data-anchor-id="the-problems-of-using-llms-to-write-for-you">The Problems of Using LLMs to Write for You</h2>
<p>One of the main issues I encountered was losing my “voice.” The articles didn’t seem like something I would write. Even though the final versions were at least 70% written by me, something felt off. Sometimes the tone was too happy, and other times it was filled with comparisons that I wouldn’t make. It just didn’t feel like me.</p>
<p>Another problem was the “fabrications” (previously called “hallucinations”): LLMs tend to create plausible but false examples. For instance, while writing about Alice in Wonderland for an upcoming post, GPT-4 fabricated a fact that would have been perfect for my story if it were true: Alice goes through a door with the number 42 on it. However, she doesn’t. These fabrications are time-consuming to review and remove. They were interesting and plausible, but verifying them took time, ultimately costing me more than saving me time.</p>
</section>
<section id="what-worked-well" class="level2">
<h2 class="anchored" data-anchor-id="what-worked-well">What Worked Well</h2>
<p>Some aspects of using LLMs worked really well. Generating images for blog posts using Stable Diffusion is something I’ll definitely continue doing. Searching for suitable, free-to-use images can be time-consuming. Generating images using AI is much faster, and the results are usually good enough, often exceeding my expectations, especially when I use my dog.</p>
<p>Another useful feature was converting a text post into a more structured Quarto Markdown file with a header and sections. While it’s not a significant time-saver, it improves the organization with minimal effort, making it worthwhile.</p>
<p>Creating titles for my posts also worked well. I am used to writing posts for LinkedIn, which don’t have titles. An LLM can read a text and generate a suitable title in seconds, usually doing a much better job than I would. This is another time-saving benefit.</p>
<p>Lastly, LLMs can check my grammar. As a non-native English speaker, I make many mistakes, but a single pass of an LLM improves my writing without sacrificing my “voice.”</p>
</section>
<section id="using-the-semantic-kernel" class="level2">
<h2 class="anchored" data-anchor-id="using-the-semantic-kernel">Using the Semantic Kernel</h2>
<p>This weekend, I began using the Microsoft Semantic Kernel to chain several LLM actions together. I’m still learning how to use it, but I’m already impressed. I’m using it to generate titles, fix my grammar, create images, and convert my text into a Quarto Markdown file. I’ll soon write a blog post teaching how to use the Semantic Kernel in Python. If you can’t wait, you can see how I’m using it by looking at the source code for my blog on GitHub.</p>


</section>
</section>

 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-05-23-my-experience-using-large-language-models-to-write-blog-posts.html</guid>
  <pubDate>Tue, 23 May 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/openai_blogging.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Copilot’s AI Weaknesses Highlight Early Days of AI</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-04-07-copilot-s-ai-weaknesses-highlight-early-days-of-ai.html</link>
  <description><![CDATA[ 



<p>As a software developer, I have been using GitHub Copilot quite a lot in my daily work. It’s an AI-powered code suggestion tool that has been saving me a lot of time. However, I recently stumbled upon an unexpected weakness of Copilot - it’s not very good at very new APIs.</p>
<p>The other day, I was using the new ChatCompletion API from GPT, and my Copilot didn’t know about it. It kept pushing me to the older Completion API. It made me realize that these AI-powered tools are still learning and growing. It will be interesting to see how these tools will balance new and established APIs in the future.</p>
<p>Instead of being frustrated, I think it’s a good thing that Copilot is not perfect. It’s a good reminder that we are still in the early days of AI, and there is still a lot of room for improvement in AI-powered tools.</p>
<p>Moreover, this makes me less worried about AI taking over the world. If AI decides to attack, it may use swords and shields, not the latest weapons, because it has a lot more battles with swords and shields in its training set. In conclusion, while we should still be cautious about the power and influence of AI, we should also embrace its imperfections and use it as a tool to make our lives easier.</p>



 ]]></description>
  <guid>https://www.meyerperin.com/posts/2023-04-07-copilot-s-ai-weaknesses-highlight-early-days-of-ai.html</guid>
  <pubDate>Fri, 07 Apr 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/fancy_schnauzer.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Zotero for Citation Management and Bibliography Creation</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-03-29-zotero.html</link>
  <description><![CDATA[ 



<section id="zotero-vs-mendeley-a-comprehensive-comparison" class="level2">
<h2 class="anchored" data-anchor-id="zotero-vs-mendeley-a-comprehensive-comparison">Zotero vs Mendeley: A Comprehensive Comparison</h2>
<p>When it comes to managing research citations and bibliographies, two popular tools are often compared: Zotero and Mendeley. While both software programs are similar in many ways, Zotero offers certain advantages that make it a better choice for scholars and researchers.</p>
<p>The issue of storage is also worth noting. Zotero’s unlimited storage for references and attachments is a definite plus, whereas Mendeley’s free version allows only 2GB of storage. This limitation can affect researchers who work with vast amounts of data and documents as Zotero’s capacity ensures all the research materials can be kept in one place and accessed easily.</p>
<p>Zotero’s customizable interface is also an advantage, allowing users to tailor the software to their specific needs. This is in contrast to Mendeley, which has a less customizable interface that may not be as user-friendly for some. Additionally, Zotero’s open-source nature allows for greater flexibility and customization, giving users the freedom to create their own plugins and add-ons or modify existing ones.</p>
<p>Lastly, the community-driven development model of Zotero is a key differentiating factor. The developers are highly responsive to user feedback and suggestions, making Zotero a constantly evolving and improving product. Mendeley, on the other hand, has a corporate-driven development model, with less emphasis on community involvement.</p>
<p>Overall, while Mendeley is a useful tool, Zotero is the superior choice for scholars and researchers. Its seamless integration with word processors, unlimited storage, customizable interface, open-source nature, and community-driven development model make it the clear winner. So, if you’re looking for a reliable and efficient citation management and bibliography creation tool, look no further than Zotero.</p>


</section>

 ]]></description>
  <category>technology</category>
  <guid>https://www.meyerperin.com/posts/2023-03-29-zotero.html</guid>
  <pubDate>Wed, 29 Mar 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/diffused_professor.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>How to Use Stable Diffusion from Hugging Face</title>
  <dc:creator>Lucas A. Meyer</dc:creator>
  <link>https://www.meyerperin.com/posts/2023-03-20-stable-diffusion-with-diffusers.html</link>
  <description><![CDATA[ 



<p>Recently, I started to automate a lot of what I do on LinkedIn. I am using AI generators to improve my text and to generate images for my blog posts. In this post, I’ll show how I am generating images for my blog and for LinkedIn with Stable Diffusion v2.1.</p>
<section id="how-to-use-stable-diffusion-from-hugging-face" class="level1">
<h1>How to Use Stable Diffusion from Hugging Face</h1>
<p>Stable Diffusion is a text-to-image model that can, among other things, generate high-resolution and photo-realistic images from any text input. It uses a diffusion process to gradually refine an image from noise, guided by the text condition.</p>
<p>Hugging Face is an open-source provider of machine learning technologies. Their platform offers a variety of tools that allow developers to build and train AI models. One of these tools is Diffusers, a library that enables easy access and inference with diffusion models such as Stable Diffusion.</p>
<p>In this tutorial, I will show you how to use Stable Diffusion from Hugging Face in a few simple steps.</p>
<section id="step-0-optional-install-pytorch-and-log-in-to-hugging-face" class="level2">
<h2 class="anchored" data-anchor-id="step-0-optional-install-pytorch-and-log-in-to-hugging-face">Step 0 (optional): Install PyTorch and log in to Hugging Face</h2>
<p>If you haven’t already, you need to install PyTorch and log in to Hugging Face. I’m installing on Windows 11:</p>
<pre><code>pip3 install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117</code></pre>
<p>You need to have a Hugging Face account to download models. To login to hugging face, create an account on the hugging face website and then use:</p>
<pre><code>huggingface-cli login</code></pre>
</section>
<section id="step-1-install-diffusers" class="level2">
<h2 class="anchored" data-anchor-id="step-1-install-diffusers">Step 1: Install Diffusers</h2>
<p>To use Stable Diffusion, you need to install Diffusers, which is available on PyPI. You can install it with pip. I usually suggest that you create a new virtual environment with <code>python -m venv .venv</code> before installing the library.</p>
<pre><code>pip install diffusers</code></pre>
</section>
<section id="step-2-load-stable-diffusion" class="level2">
<h2 class="anchored" data-anchor-id="step-2-load-stable-diffusion">Step 2: Load Stable Diffusion</h2>
<p>Next, you need to load the Stable Diffusion model from Hugging Face Hub. You can choose from several checkpoints that have been trained on different datasets and for different durations. For example, you can load the stable-diffusion-2-1 checkpoint with:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> diffusers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StableDiffusionPipeline</span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># you can also download the model manually</span></span>
<span id="cb4-4">pipeline <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StableDiffusionPipeline.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stabilityai/stable-diffusion-2-1-base"</span>)</span>
<span id="cb4-5"></span>
<span id="cb4-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># if you have a CUDA-enabled GPU, you can use it to speed up image generation quite a lot</span></span>
<span id="cb4-7">pipeline <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline.to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span></code></pre></div>
<p>This will download the model weights and configuration to your local cache.</p>
</section>
<section id="step-3-generate-images" class="level2">
<h2 class="anchored" data-anchor-id="step-3-generate-images">Step 3: Generate Images</h2>
<p>Now you are ready to generate images with Stable Diffusion. You just need to provide a text prompt as input. For example, the following code will generate an image of a “jedi schnauzer”:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"jedi schnauzer"</span></span>
<span id="cb5-2">image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>prompt, height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>, num_inference_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>, guidance_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.5</span>).images[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<p>The pipeline method will return an image object that you can display or save as you wish. You can also customize some parameters of the generation process, such as the number of samples, the resolution, and the number of diffusion steps. For more details, please refer to the documentation of Diffusers (https://huggingface.co/docs/diffusers/index).</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this tutorial, we have shown you how to use Stable Diffusion from Hugging Face with Diffusers library. We hope you enjoyed this tutorial and found it useful for your projects. If you have any questions or feedback, please feel free to contact us or open an issue on GitHub.</p>
<p>My code is available on GitHub (https://github.com/lucas-a-meyer/diffusers-experiments/).</p>


</section>
</section>

 ]]></description>
  <category>technology</category>
  <guid>https://www.meyerperin.com/posts/2023-03-20-stable-diffusion-with-diffusers.html</guid>
  <pubDate>Mon, 20 Mar 2023 13:00:00 GMT</pubDate>
  <media:content url="https://www.meyerperin.com/images/ai_schnauzer.png" medium="image" type="image/png" height="144" width="144"/>
</item>
</channel>
</rss>
